[{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://www.remotelycurious.net/author/alex-hadjinicolaou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/alex-hadjinicolaou/","section":"authors","summary":"","tags":null,"title":"Alex Hadjinicolaou","type":"authors"},{"authors":[],"categories":["sysadmin"],"content":"A modern operating system is supported by hundreds of processes that handle communication between the user and the computer hardware. Most of the time, we deal with interactive processes (i.e., applications), but behind the curtain are a myriad of services; processes that run in the background and support various low-level functions of the operating system, such as logging and memory management.\nTo better understand how services are managed in Linux, I decided to make my own service and manage it through systemd, the service manager used by CentOS 8. It\u0026rsquo;s definitely not the most exciting topic in the world, so to make things fun, I decided to develop a Python script that monitors the keyboard for certain words (and delivers unwanted feedback) and make a service out of it.\n  Fig. 1. Meet Judgy, the service that has an opinion about your browsing habits.   Table of Contents  Understanding systemd  Service management Unit files     System state   Creating services  A quick warmup     Unit file overrides     Getting judgy       Summary   Understanding systemd Systemd manages things called units that represent different kinds of system resources. Each type of resource is handled by a specific type of unit. Here are three examples:\n sshd.service, the service unit which manages the OpenSSH service, boot.mount, the mount unit that specifies which file system gets mounted to the /boot directory, dbus.socket, the socket unit that activates the D-Bus message bus (a service that handles communication between applications) to process intercepted messages.  Units can also describe devices, timers, and more abstract things, like targets (groups of units) and slices (reservations of CPU/RAM/storage/bandwidth for groups of processes). For now, just appreciate that the notion of a unit is a very broad one.\n There are many units. Running # systemctl list-unit-files on my system yields a total of 421 units, with roughly a third of these being service units.   Although systemd is massively multi-purpose and capable of handling all kinds of system tasks (with perhaps the most important being system initialization), this writeup will focus on using systemd for service management.\nService management Most of the time, a service will sit in the background and keep out of trouble. When issues do arise, we need a way to interact with the service by querying its status (e.g., \u0026ldquo;are you still alive?\u0026quot;) or by stopping and (re)starting the service.\nThese are achieved with # systemctl \u0026lt;verb\u0026gt; \u0026lt;name\u0026gt;.service, using the verb\n start, to start a systemd service, stop, to ask the service to stop (as opposed to killing it), status, to get general information about the service, restart, to stop and then start the service.  We can check on the status of the OpenSSH service, for example, by running # systemctl status sshd.service. The output (Fig. 2) gives us a lot of useful information, including some manpage references (Docs) and whether the service is\n loaded (systemd has read the service\u0026rsquo;s configuration file) versus not-found, enabled (the service will run after booting the system) versus disabled, active (running) versus active (exited) or inactive (dead).    Fig. 2. Querying the status of the OpenSSH daemon.   At the end of this output, you can see the last few lines of OpenSSH\u0026rsquo;s logging output, which can often be helpful for diagnosing problems. The full session log can be viewed with # journalctl -u sshd.service, which queries systemd\u0026rsquo;s journal, a single binary file that collects all messages from the operating system and userland applications.\n It\u0026rsquo;s important to discriminate between an active service (i.e., running at the moment) and an enabled service, which runs at boot. To ensure that a service will start at boot, run # systemctl enable \u0026lt;name\u0026gt;.service.   Unit files If you read the \u0026lsquo;loaded\u0026rsquo; line of the above output, you will find a reference to a file located in /usr/lib/systemd/system/sshd.service. This unit file defines the OpenSSH service, including how and when to start it, whether to restart it after failure, and important environment variables for configuration. Essentially, unit files are the means by which systemd understands system resources.\nLet\u0026rsquo;s take a look.\n/usr/lib/systemd/system/sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.target Wants=sshd-keygen.target [Service] Type=notify EnvironmentFile=-/etc/crypto-policies/back-ends/opensshserver.config EnvironmentFile=-/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS $CRYPTOPOLICY ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target  A service unit file consists of three sections, denoted using square brackets. The [Unit] section above contains four directives that together describe the unit and define its dependencies. In this section, the most important directives are\n After, used to direct systemd to start the configured service after the listed units become fully functional, and Wants, to list units that should be started together with the configured service.  In our case, After=network.target sshd-keygen.target makes sure that OpenSSH is started after two (target unit) resources become available: (a) the network management stack, allowing applications to access the network, and (b) OpenSSH\u0026rsquo;s keygen server, which is used by OpenSSH to generate keys for public key authentication.\n Note that specifying After=network.target doesn\u0026rsquo;t guarantee that your service will start after your network interfaces are online! The purpose of this directive value is to allow your network-dependent service to terminate properly when the system is shutdown. To ensure a service starts after the network comes online, use After=network-online.target.   The [Service] section describes how to (re)start and stop the service. Different Type directive values determine how the process should start, with Type=notify telling the service to send a signal to systemd when it is active. The EnvironmentFile directives are used to load variables (OPTIONS, CRYPTOPOLICY, MAINPID) contained in the listed files, which are used by ExecStart and ExecReload to configure the execution and termination of the service. If the service ends unexpectedly, Restart=on-failure tells systemd to restart the service, in this case after 42 seconds.\n You may have noticed the hyphens preceding some directive values; these indicate \u0026lsquo;optional\u0026rsquo; directives. Normally, if any of the directives leads to an error (either because a listed file doesn\u0026rsquo;t exist, or a listed process fails to execute), systemd will indicate that the service has failed. In our case, even if the files listed in the above EnvironmentFile directives are missing, the show will go on.   Lastly, the [Install] section holds information about how to install the service, so that it can be started at boot. The directives in this section are processed when evoked by systemctl enable or systemctl disable. It is common to find WantedBy=multi-user.target here; this specifies that systemd should start the service only when the system has reached a certain state, defined by the multi-user.target unit. If the system cannot reach this state, the service will not automatically start, even if it has been enabled.\nSystem state It\u0026rsquo;s worth expanding on what we mean by state. After powering on a CentOS Linux system and loading the kernel, systemd is the first process to start ( PID 1). Systemd will then proceed to activate services and other units until the system has reached some requested (default) state, represented by a systemd target. For example, if systemd achieves the multi-user.target state, multiple users can log into the system and access the network, but they are unable to start a graphical shell and are thus restricted to a text-based shell. Booting into the rescue.target state is usually reserved for emergency situations where the system cannot start normally. In this case, systemd will only start the bare minimum set of system resources, avoiding the activation of network interfaces and other nonessential peripheral devices. This allows the root user to try and reverse any changes that harmed the regular initialization process.\nThe table below lists the available systemd targets in CentOS, together with their associated outcomes and runlevels (i.e., the equivalent of state in other init systems). By default, CentOS will attempt to achieve either the multi-user.target state or the graphical.target state, with the latter for GUI-based installations.\nTable 1. Systemd targets in CentOS.\n--    Runlevel Target Outcome     0 poweroff.target üîå System shutdown   1 rescue.target üöë Single-user \u0026ldquo;safe mode\u0026rdquo; shell   3 multi-user.target ‚å®Ô∏è Non-graphical multi-user shell   5 graphical.target üë®‚Äçüíª Graphical multi-user shell   6 reboot.target ‚ö° System reboot    These targets are special in that they can be used to switch the current state of the computer using the # systemctl isolate \u0026lt;name\u0026gt;.target command. For instance, you can restart your computer with # systemctl isolate reboot.target. This is made possible by the inclusion of the AllowIsolate=yes directive in each of these unit files.\nAt this point we know enough to start playing around with our own services. Time to get your hands dirty!\nCreating services We will deal with two custom services: (a) the Hello service, which will serve as a kind of warmup to reinforce some important concepts (while introducing some new ones), and (b) the Judgy service, the ultimate subject of this writeup.\nBefore we get into things, a quick note about where systemd expects unit files:\n /usr/lib/systemd/system, for default unit files that come with RPM packages, /etc/systemd/system, for custom unit files (e.g., made using systemctl edit), /run/systemd/system, for automatically generated unit files.  That means our unit files are going in /etc/systemd/system. You can create the Hello unit file the old-fashioned way (e.g., via vim) or by running # systemctl edit --force --full \u0026lt;name\u0026gt;.service, which will bring up a text editor for you to work with.\n If units with identical names exist in more than one of the above locations, those in /run will take precedence over others. Next in line are unit files in /etc, with units in /usr/lib being of lowest priority.   A quick warmup Let\u0026rsquo;s introduce the Hello service unit file. As you can see, there\u0026rsquo;s not a lot to it.\n/etc/systemd/system/hello.service [Unit] Description=Hello service [Service] ExecStart=/usr/bin/bash /data/hello.sh 10 meepmeep  Once activated, the service will execute a script called hello.sh, shown below. When executed, it first lists any command line arguments, and if the first argument ARG1 is a positive integer, sleeps for ARG1 seconds. Simple enough.\n/data/hello.sh HMS=$(date +\u0026quot;%H:%M:%S\u0026quot;) printf \u0026quot;\\n[%s] HELLO service came online.\\n\u0026quot; ${HMS} # print out command line arguments if [ \u0026quot;$#\u0026quot; -ge 1 ]; then i=1; printf \u0026quot;Supplied arguments:\\n\u0026quot; for ARG in \u0026quot;$@\u0026quot;; do printf \u0026quot;\\targ%d: %s\\n\u0026quot; $i $ARG i=$((i + 1)); done fi # sleep for ARG1 seconds if ARG1 is a positive integer if [ -n \u0026quot;$1\u0026quot; ] \u0026amp;\u0026amp; [ \u0026quot;$1\u0026quot; eq \u0026quot;$1\u0026quot; ] 2\u0026gt;/dev/null; then sleep $1 fi HMS=$(date +\u0026quot;%H:%M:%S\u0026quot;) printf \u0026quot;[%s] HELLO service is done.\\n\\n\u0026quot; ${HMS}  Here\u0026rsquo;s the output of the script if we run it normally:\n# ./hello.sh 10 meepmeep [13:23:56] HELLO service is online. Supplied arguments: arg1: 10 arg2: meepmeep [13:24:06] HELLO service is done.  If we start the service with # systemctl start hello.service and quickly check its status, we can see the output of the script within the logging output.\n  Fig. 3. Querying the Hello service while it is still operational.   After ten seconds of sleep, the script is done and the service becomes inactive.\n  Fig. 4. The Hello service is done.   That was a pretty straightforward example, so let\u0026rsquo;s build on it to show something useful.\nUnit file overrides We might not always want to start our service with the same directives and parameters. Indeed, there might be times where we want to override some of them while keeping others. This is where drop-in units come in handy.\nHere\u0026rsquo;s the situation: we like our Hello service, but we want to make two changes:\n (a) we want to supply input arguments to hello.sh from a file, (b) once the service becomes inactive, it should restart after sixteen seconds.  To achieve the first goal, we will make hello.config, a configuration file from which systemd will extract the script\u0026rsquo;s input arguments, shown below.\n/data/hello.config DELAY=16 OTHERARG=testing.one.two.three  We will now create a drop-in unit that loads these variables with the EnvironmentFile directive (and uses them when overriding the previous ExecStart directive). The unit also injects two new directives that satisfy our second goal. You can use # systemctl edit hello.service to create the drop-in file, nested in a hello.service.d folder.\n/etc/systemd/system/hello.service.d/override.conf [Unit] Description=Hello service [Service] EnvironmentFile=/data/hello.config ExecStart= ExecStart=/usr/bin/bash /data/hello.sh $DELAY $OTHERARG Restart=always RestartSec=16s  Pay attention to the empty ExecStart directive. This is done to eliminate the parent directive; without it, the complete unit file (base plus override) would in effect have two ExecStart directives, leading to an error.\n After making changes to your unit files, be sure to register them in systemd using systemctl daemon-reload.   Now if we fire up our service, we will see that the script is now working with the new input arguments. Note the new Drop-In line, which lists the overriding unit file.\n  Fig. 5. The upgraded Hello service, running with our new parameters.   If we query the service after it has expired, we can see that the Active line contains activating (auto-restart). This indicates that the service is scheduled to be restarted, which is evidence that our new configuration has taken effect.\n  Fig. 6. \u0026ldquo;I\u0026rsquo;ll be back.\u0026rdquo;   Getting judgy We have made it to the final act. The goal here, as mentioned at the outset, is to run a Python script that monitors a specific user\u0026rsquo;s keypresses and delivers (juvenile) notifications to the user, depending on the content of the user input. The solution will, of course, be implemented as a systemd service.\nJudgy\u0026rsquo;s source (shown below) makes use of two important resources:\n  keyboard, a lightweight event hook library written in Python, and  notify-send, a program to send desktop notifications, provided by libnotify.  After registering process_key() as the keypress callback, the script will indefinitely sleep and process keypresses, buffering all typed alphabetical characters. If the user presses a non-alphabetical key, Judgy will test the buffer for objectionable content (defined in the *_words wordlists) with pass_judgement() before clearing the buffer. Should the user have typed any words contained in these wordlists, judgement will be rendered in the form of a graphical notification delivered to the user with send_notification(). Judgy will continue to process keypresses until the user enters the safe word (scram).\n Some important points:\n judgy needs to be supplied with the username of the (logged-in) desktop user, notify-send will not work without the D-Bus address of the desktop user, keyboard (and therefore judgy) needs to be run as root.  As for the service unit, we will opt for simplicity. Judgy is started using sudo and a Python interpreter (with btables being the username of the desktop user). You could add an [Install] section and start Judgy at boot, but that would likely get very irritating.\n/etc/systemd/system/judgy.service [Unit] Description=Judgy service [Service] ExecStart=/usr/bin/sudo /usr/bin/python3 /data/judgy.py btables  Start the service via # systemctl start judgy.service and you\u0026rsquo;re in business. You can stop the service either through systemctl or by entering the safe word.\nSummary If you made it through the writeup, congratulations! By now, you likely have a decent grasp of the basics of service management, as well as an appreciation for systemd\u0026rsquo;s various capabilities. Although I am no sysadmin, the process of making this writeup has improved my understanding of how systemd operates under the hood, while at the same time making me realize how much more there is to this software monolith\u0026hellip;\n","date":1608995514,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608995514,"objectID":"3aa4587a5fa01beb44ccf795164ae044","permalink":"https://www.remotelycurious.net/post/systemd-shenanigans/","publishdate":"2020-12-26T10:11:54-05:00","relpermalink":"/post/systemd-shenanigans/","section":"post","summary":"Learning about service management with the help of an unfriendly Python script.","tags":["systemd","python","bash","services","linux"],"title":"Shenanigans with systemd","type":"post"},{"authors":[],"categories":["analysis","ml.doc"],"content":" This writeup belongs to a series of notes based on MITx 6.86x, an introductory machine learning course. You can find the previous writeup here.   Table of Contents  Allowing room for error  Margin boundaries The signed distance Signed and unsigned distance   Learning as optimization  Average loss Regularization The objective function Bias-variance trade-off Gradient descent Stochastic gradient descent   Summary   Allowing room for error While the perceptron algorithm is easy to understand, the fact that it only works for linearly separable data really limits its application. Data collected in the real world are often measured with some error. They are noisy. Sometimes training examples can be accidentally mislabeled. There are many good reasons for an algorithm to allow some room for error and not let \u0026ldquo;the perfect be the enemy of the good\u0026rdquo;.\nLet\u0026rsquo;s take a look at two different linear classifiers (Fig. 1). On the left we have a decision boundary that is extremely close to one of the training examples. The two dashed lines on either side are margin boundaries that expand until one of them hits a training example.\n  Fig. 1. Two classifiers, each with different margin sizes.   If you were to choose which classifier you would prefer, you would probably choose the one on the right, the one with a large margin. You can see that if the $(x_1, x_2)$ coordinates had more jitter, the classifier on the left might misclassify the negative training example sitting on the negative margin boundary. With all else being equal, we would prefer to use large margin classifiers that are more tolerant of natural variation.\nTo incorporate the idea of margins into our classification algorithms, we will formulate learning as an optimization problem that strikes a balance between two competing goals, the first of these being to achieve large classifier margins.\nMargin boundaries As seen earlier, linear margin boundaries are lines that sit on either side of the decision boundary, one for each label region in the feature space. Since the margins are parallel to the decision boundary $(\\theta \\cdot x + \\theta_0 = 0),$ the margins take the form $\\newcommand{\\norm}[1]{|| #1 ||}$\n$$ \\theta \\cdot x + \\theta_0 = d.$$\nThe positive margin boundary, residing within the positive feature space region, is defined as $\\theta \\cdot x + \\theta_0 = 1$ while the negative decision boundary on the other side is defined as $\\theta \\cdot x + \\theta_0 = -1$. (Fig. 2).\n  Fig. 2. Positive and negative margin boundaries.   We can get a sense for how to control the width of the margins by considering the dynamics of $f(x) = \\theta \\cdot x + \\theta_0$. As we move away from the decision boundary and towards the positive margin boundary, $f(x)$ increases at a rate proportional to $\\norm{\\theta}$, the magnitude of $\\theta$. If we want to speed up how quickly we arrive at $f(x) = 1$ (and in doing so reduce the margin) we need to use larger values of $\\norm{\\theta}$.\nEarlier, I mentioned that our optimization process has two competing priorities, one of which is to use large margins. The other priority seems quite natural: to achieve the highest possible classification accuracy on the training set.\nThe signed distance To optimize training set performance, it is not enough to simply know whether the prediction is right or wrong, as measured by the training error $E_N$. We need to somehow measure how far away each training example is from the decision boundary. That is, we need to consider and quantify the notion of distance.\n What follows is a quick derivation of the signed distance from a point to a line. Try to follow the steps if you can, but otherwise feel free to skip to the next section.   Imagine we have a training example $P$ sitting some distance $d$ away from the decision boundary (Fig. 3). The point $Q$ is any point $x'$ that sits on the decision boundary, such that $\\theta \\cdot x\u0026rsquo; + \\theta_0 = 0$.\n  Fig. 3. Sketching the distance $d$ between the line and point $P$.   Since $d$ is the smallest possible distance, the vector $\\overrightarrow{RP}$ is perpendicular to $\\overrightarrow{QR}$ and so the points $PQR$ form a right-angled triangle. The distance $d$ can then be expressed using basic trigonometry,\n$$d = \\norm{\\overrightarrow{RP}} = \\norm{\\overrightarrow{QP}} \\textrm{ cos }\\alpha.$$\nWe also know the angle $\\alpha$ is related to $\\overrightarrow{QP}$ and $\\theta$ by the dot product,\n$$ \\theta \\cdot \\overrightarrow{QP} = \\norm{\\theta} \\norm{\\overrightarrow{QP}} \\textrm{ cos }\\alpha .$$\nConsolidating these two equations, together with the fact that $\\overrightarrow{QP} = x - x\u0026rsquo;,$ yields the final expression for the signed distance,\n$$d_s(x) = \\frac{ \\theta \\cdot \\overrightarrow{QP} }{\\norm{ \\theta} } = \\frac{ \\theta \\cdot x - \\theta \\cdot x\u0026rsquo; }{\\norm{ \\theta} } = \\frac{ \\theta \\cdot x + \\theta_0 }{\\norm{ \\theta} }. $$\nSigned and unsigned distance What does it mean for $d$ to be signed? As a quick illustration, consider how a hypothetical classifier might deal with some positive training examples (Fig. 4). We can see that the points \u0026ldquo;deepest\u0026rdquo; within the positive region, $x_1$ and $x_2$, are sitting some positive distance from the decision boundary because $\\theta \\cdot x + \\theta_0$ is positive for each point.\n  Fig. 4. Four training examples with varying degrees of loss.   The example $x_2$ is sitting right on the positive margin boundary. Since any point on the positive margin boundary satisfies $\\theta \\cdot x + \\theta_0 = 1$, this means\n$$d_s(x_2) = \\frac{\\theta \\cdot x_2 + \\theta_0}{\\norm{\\theta}} = \\frac{1}{\\norm{\\theta}}.$$\nWe can also see that $x_3$ sits right on the decision boundary, and so\n$$d_s(x_3) = 0.$$\nWhat about $x_4$? The dot product of $\\theta$ and $x_4$ will be negative, as will be the distance. We know that its distance must be something between zero and $-1/\\norm{\\theta},$ the signed distance to the negative margin boundary.\nWe can modify the signed distance slightly to form an expression for the unsigned distance of a training example from the decision boundary by using the example\u0026rsquo;s label,\n$$d(x^{(i)}) = \\frac{y^{(i)} ( \\theta \\cdot x^{(i)} + \\theta_0 )}{\\norm{\\theta}}.$$\n When the training examples are correctly classified, the signs of the label $y^{(i)}$ and $\\theta \\cdot x^{(i)} + \\theta_0$ will match, and their product will be positive. Otherwise, their product will be negative. This sign \u0026ldquo;agreement\u0026rdquo; will come up again very soon, where we discuss loss functions.   It\u0026rsquo;s time to put all the pieces together.\nLearning as optimization There has been a lot of ground covered since we first brought up the idea of reframing the learning process as an optimization problem. To recap, there are two competing priorities:\n achieving high training set classification accuracy, and obtaining large classifier margins.  We are going to formulate an objective function $J$ that incorporates these priorities as two separate components: (a) the average loss, and (b) the regularization component. The idea is then to find the classifier parameters $\\theta$ and $\\theta_0$ that minimize $J,$ where\n$$ J(\\theta, \\theta_0) = \\textrm{average loss} + \\lambda \\cdot \\textrm{regularization}.$$\nThat lambda parameter $\\lambda$ is the regularization term. This is an important parameter that we will soon discuss, but for now, think of it as a dial that we can tweak to balance our two priorities. Let\u0026rsquo;s now talk about the first component.\nAverage loss The average loss component (oddly enough!) makes use of a loss function. The goal of a loss function is to quantify the error of a prediction. You have already seen the 0-1 loss function $f(z^{(i)}, y^{(i)}) = [\\![ z^{(i)} \\neq y^{(i)} ]\\!],$ which takes the value 1 when the prediction $z^{(i)}$ doesn\u0026rsquo;t match the example label $y^{(i)}$, and zero otherwise.\n The notation $z^{(i)}$ above is used to indicate an \u0026ldquo;agreement\u0026rdquo; term between the classifier output for the $i$-th training example and its corresponding label,\n$$z^{(i)} = y^{(i)} (\\theta \\cdot x^{(i)} + \\theta_0).$$\n  Another common loss function is the hinge loss function,\n$$\\textrm{Loss}_h(z) = \\begin{cases} 1-z \u0026amp; \\text{if $z\u0026lt;1$} \\\\\n0 \u0026amp; \\text{otherwise} \\end{cases}$$\nLet\u0026rsquo;s use the hinge loss function on our (positive) training examples from the last figure. Below we have a plot of the hinge loss function, with the loss of each example overlaid as a blue dot (Fig. 5). Points $x_1$ and $x_2$ incur zero loss, since $z^{(i)} = y^{(i)} (\\theta \\cdot x^{(i)} + \\theta_0) \\geq 1$ for both examples. The point $x_3$, sitting on the decision boundary, incurs an agreement value $z^{(3)} = 0$, which gets mapped to $\\textrm{Loss}_h(z^{(3)}) = 1 - z^{(3)} = 1.$\nWe can see that once a point starts to invade its corresponding margin boundary (located at $z=1$ for the positive label), the hinge loss increases linearly as a function of distance.\n  Fig. 5. The hinge loss function (thick black line), with the loss values for each training example in Fig. 4. Blue shading indicates values of $z$ for which positive training examples are correctly classified.   Using this loss function, the average loss can now be written as\n$$\\textrm{average loss} = \\frac{1}{N} \\sum_{i=1}^{N}\\textrm{Loss}_h(y^{(i)} ( \\theta \\cdot x^{(i)} + \\theta_0 )).$$\nRegularization At this stage you may have a vague idea that large margin classifiers are a good thing, and that regularization is supposed to help find such classifiers. We will expand on these ideas in this section. The topic of regularization is definitely worth more coverage, since it is critical in helping us avoid the dreaded problem of overfitting.\nModels that suffer from overfitting are in a sense, too smart for their own good. Overfit models are too familiar with the training data, contorting themselves to minimize training errors at the expense of being useful for general application.\nWe will illustrate this problem with some synthetic data: twenty points from a quadratic function, corrupted by some noise. Now let\u0026rsquo;s fit three different polynomials to this data:\n a linear function, a quadratic function (i.e., a proper fit), and a 10th-order polynomial.    Fig. 6. Fitting three different k-order polynomials to data generated by a quadratic function.   The overfit model has some issues. It is overly complex for the data: while the average error (or loss) across the training data might be quite low, it is completely useless beyond the limited range of our training data. The linear fit faces the same problem but for the opposite reason: it is too simple to capture the underlying signal.\nIn the context of our optimization problem, classification accuracy for the training set is improved by minimizing the average loss component. How do we maximize the classifier margins? To do this, we need to minimize $\\norm{\\theta}$. This is the same task as minimizing $\\norm{\\theta}^2$. By convention, the regularization component is specified as\n$$\\textrm{regularization} = \\frac{1}{2} \\norm{\\theta}^2.$$\nThe objective function We are finally ready to look at the objective function in all its glory, the function that we are going to minimize to discover the parameters $\\{\\theta,\\theta_0\\}$ of our classifier:\n$$J(\\theta,\\theta_0) = \\underbrace{\\frac{1}{N} \\sum_{i=1}^{N}\\textrm{Loss}(y^{(i)} ( \\theta \\cdot x^{(i)} + \\theta_0 ))}_{\\textrm{average loss}} + \\underbrace{ \\vphantom{ \\sum_{1}^{2} } \\frac{\\lambda}{2}\\norm{\\theta}^2.}_{\\textrm{regularization}}$$\nWithin the framework of our optimization problem, we need to strike the right balance between model complexity (minimizing training loss) and model utility (maximizing classifier margins), which is done by finding a good value of $\\lambda$.\n What happens if we set $\\lambda=0$ and eliminate the regularization component? In this case, the optimization process results in a classifier that prioritizes low average loss above all else, which leads to overfitting. If we set $\\lambda$ to a really big number, we get an overly simple model that won\u0026rsquo;t learn enough from the training data to make useful predictions.   Before we discuss how to minimize the objective function, it is worth taking a quick detour to talk about what it really means to find a \u0026ldquo;good\u0026rdquo; value of $\\lambda$.\nBias-variance trade-off To get a feel for what we are trying to achieve here, let\u0026rsquo;s frame our discussion around the idea of model \u0026ldquo;complexity\u0026rdquo;, $C = \\frac{1}{\\lambda}$. That makes the objective function look like this:\n$$J(\\theta,\\theta_0) = \\frac{1}{N} \\sum_{i=1}^{N}\\textrm{Loss}(y^{(i)} ( \\theta \\cdot x^{(i)} + \\theta_0 )) + \\frac{1}{2C}\\norm{\\theta}^2.$$\nAs we increase the model complexity, the regularization component becomes less influential, with more importance placed on minimizing the training error. A model that is too complex (like that tenth-order polynomial from the last figure) will be highly sensitive to the training data \u0026ndash; if trained on another training set, the resulting model parameters and its corresponding predictions are likely to be very different. Such a model is said to exhibit high variance (Fig. 7, orange shading).\nIt is also possible to use a model that is too simple, as you have seen earlier. Notice how smaller values of $C$ place more importance on finding large margin classifiers. An underfit model does not produce accurate predictions, indicating a large bias (Fig. 7, blue shading). You can think of bias as the error inherent to your model. For example, there is a hard limit on how well you can fit a linear function to quadratic-order training data (Fig. 6).\n  Fig. 7. The bias-variance trade-off: selecting the right level of complexity $(C^{\\ast})$ to balance bias (test prediction accuracy) and variance (prediction sensitivity to different training data). Models can suffer from underfitting if $C$ is too small (blue shading) or overfitting if $C$ is too large (yellow shading).   There is one more item of interest here: the test error (Fig. 7, black curve), which is comprised of the model bias and variance. If we can minimize the test error1, we could then find $C^{\\ast}$, the optimal level of complexity that achieves low bias (high prediction accuracy on the test set) and low variance (model parameters that are not sensitive to the choice of training data). The balance between these two priorities is known as the bias-variance trade-off.\nGradient descent Let\u0026rsquo;s return to our original discussion. The goal is to find the classifier parameters $\\{\\theta,\\theta_0\\}$ by minimizing $J$, the objective function. We will now introduce gradient descent, a well-known iterative algorithm for finding these parameters.\nTo start with, we will look at what happens in a single iteration of the algorithm, for a single parameter $\\theta$ and its associated objective function $J(\\theta)$ (Fig. 8). The algorithm starts at some point $\\theta_k = \\theta'$, located to the right of the ideal value $\\theta^*$. Next, the slope (or gradient) $\\nabla_{\\theta} J = \\frac{\\partial J}{\\partial \\theta}$ is evaluated at $\\theta_k$. Finally, the algorithm computes $\\theta_{k+1}$ by taking a step in the opposite direction of the slope, such that\n$$\\theta_{k+1} = \\theta_{k} - \\eta \\cdot [\\nabla_{\\theta} J] _{\\theta_k},$$\nwhere the learning rate $\\eta$ determines the size of the step. With successive iterations, the parameter gets closer and closer to $\\theta^{\\ast}$, for which $J(\\theta^\\ast)$ is a (local) minimum.\n  Fig. 8. Sketch of an objective function $J(\\theta)$ and its derivative $\\nabla J(\\theta)$, evaluated at point $\\theta\u0026rsquo;.$    The notation for partial derivatives can be a little confusing at first. If we are dealing with a two-dimensional parameter vector $\\theta = [\\theta_1, \\theta_2]$, the gradient of $J$ with respect to $\\theta$ takes the form\n$$\\nabla_{\\theta} J = \\begin{bmatrix} \\frac{\\partial J}{\\partial \\theta_1}\\\\\n\\frac{\\partial J}{\\partial \\theta_2}\\\\\n\\end{bmatrix}_{(\\theta_1^{'},\\theta_2^{'})}$$\nwhere $\\frac{\\partial J}{\\partial \\theta_i}$ is the partial derivative of $J$ with respect to $\\theta_i$. Each $\\frac{\\partial J}{\\partial \\theta_i}$ is evaluated at its corresponding parameter value $\\theta_i^{'}.$\n  The same principles apply in higher dimensions. If we are trying to optimize two parameters $(x, y)$, then both parameters are updated simultaneously using the partial derivatives of $J,$ evaluated at the current parameter values $(x_k, y_k)$.\n$$\\begin{align*} \\begin{bmatrix} x_{k+1}\\\\\ny_{k+1}\\\\\n\\end{bmatrix} \u0026amp;= \\begin{bmatrix} x_k\\\\\ny_k\\\\\n\\end{bmatrix} - \\eta \\begin{bmatrix} \\frac{\\partial J}{\\partial x}\\\\\n\\frac{\\partial J}{\\partial y}\\\\\n\\end{bmatrix}_{(x_k,y_k)} \\end{align*}$$\nHow do we actually compute the gradient? That depends on which loss function is being used. For now we will show the general expression for the gradient, leaving out the offset parameter for cleaner notation, but either way, we can see that the gradient is just a sum of functions.\n$$\\begin{align*} \\nabla_{\\theta} J(\\theta) \u0026amp;= \\nabla_{\\theta} \\left [ \\frac{1}{N} \\sum_{i=1}^{N}\\textrm{Loss}(y^{(i)} \\theta \\cdot x^{(i)} ) \\right ] + \\nabla_{\\theta} \\left [ \\frac{\\lambda}{2}\\norm{\\theta}^2 \\right ]\\\\\n\u0026amp;= \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} \\left [ \\textrm{Loss}(y^{(i)} \\theta \\cdot x^{(i)} ) \\right ] + \\lambda \\theta \\end{align*}$$\nNote that we need to iterate over the entire dataset for each gradient update, which can be resource-intensive and oftentimes inconvenient. It is largely for these reasons that we consider an alternative algorithm, one that has become a mainstay in the modern ML practitioner\u0026rsquo;s toolbox.\nStochastic gradient descent The basic idea behind stochastic gradient descent (SGD) is to approximate the objective function gradient $\\nabla_{\\theta} J(\\theta)$ using a randomly selected sample $(x^{(i)}, y^{(i)})$ from the full dataset. The expression for the gradient then becomes\n$$\\begin{align*} \\nabla_{\\theta} J_i(\\theta) \u0026amp;= \\nabla_{\\theta} \\textrm{Loss}(y^{(i)} \\theta \\cdot x^{(i)} ) + \\lambda \\theta \\end{align*}.$$\n Remember the chain rule, which tells us that $\\frac{dL}{d\\theta} = \\frac{dL}{dz}\\frac{dz}{d\\theta}.$   Let\u0026rsquo;s assume that we\u0026rsquo;re dealing with hinge loss, whose derivative looks like this:\n$$ \\nabla_z \\textrm{Loss}_h(z) = \\begin{cases} -1 \u0026amp; \\text{if $z\u0026lt;1$} \\\\\n0 \u0026amp; \\text{otherwise} \\end{cases}$$\nThe objective function gradient for the $i$-th example now takes the form\n$$\\begin{align*} \\nabla_{\\theta} J_i(\\theta) \u0026amp;= \\begin{cases} -y^{(i)} x^{(i)} + \\lambda \\theta \u0026amp; \\text{if loss \u0026gt; 0}\\\\\n\\lambda \\theta \u0026amp; \\text{if loss = 0} \\end{cases} \\end{align*}$$\nAs you might guess, this \u0026ldquo;cheap\u0026rdquo; gradient tends to increase the number of iterations needed to converge on the optimized model parameters. On the other hand, each iteration can be computed much more rapidly, with especially good performance made possible on high-dimensional datasets.\nSummary The objective function is an important construct that lets us reframe machine learning problems as optimization problems, which can be solved with the help of some calculus. We have discussed a handful of important considerations that apply to most (if not all) ML problems, but there is of course so much more to learn. For those wondering where to go from here, my suggestion would be to read up about different types of regularization and how they can be used to achieve different outcomes (e.g., lasso regularization can be used to eliminate unhelpful predictors in a regression model).\n  Although it is not possible to know the exact test error, there are ways to approximate it, such as through cross-validation. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1606865800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606865800,"objectID":"6f3557231d5b9a49cacbab5a6ff734d9","permalink":"https://www.remotelycurious.net/post/ml-doc-01-2-learning-as-optimization/","publishdate":"2020-12-01T19:36:40-04:00","relpermalink":"/post/ml-doc-01-2-learning-as-optimization/","section":"post","summary":"Finding a good classifier by stumbling in its general direction.","tags":["machine-learning","overfitting","underfitting","classification","objective-function","regularization","gradient-descent","bias-variance-tradeoff"],"title":"ml.doc (1.2): Learning as optimization","type":"post"},{"authors":[],"categories":["analysis","ml.doc"],"content":"Over the last few weeks I\u0026rsquo;ve been working through MIT\u0026rsquo;s machine learning course (6.86x). The course\u0026rsquo;s emphasis on understanding the core concepts really makes you think about the data and whether a given algorithm is the right tool for the job. This approach would benefit those who are new to machine learning and looking to employ ML algorithms in their own work. On the other hand, the course itself requires some mathematical maturity (not to mention a bucketload of undergraduate algebra and calculus) which can make the material hard to digest. A little exposition in the right places would go a long way towards helping new practitioners use these new tools more effectively in their projects.\nTo address this thought bubble (and reinforce my own understanding), I\u0026rsquo;ve decided to write up some key ideas introduced in MITx 6.86x so as to make them more accessible to a general audience. Think of each writeup as being inspired by the MIT approach, but with some extra material in places to help absorb the ideas.\n To get the most out of these writeups, you should be familiar with basic machine learning concepts, including things such as the difference between supervised and unsupervised learning, and the importance of using separate training and testing datasets. It\u0026rsquo;s also useful to have at least some rusty linear algebra and calculus skills under your belt.   Table of Contents  Overview  Measuring error Sketching the goal   A mathematical translation  The decision boundary The binary linear classifier Linear separability   Teaching the classifier  The perceptron  Number of iterations The offset update     Summary   The job of a classifier is to take some input data and figure out how to label it. Many successful applications of machine learning involve classification, ranging from recommender systems to spam and fraud detection to medical diagnosis. This writeup will be focused on classifiers that are both binary (i.e., two output label choices) and linear, where the label output is a linear function of the inputs.\nOverview A classifier $h$ is a function that maps an input feature vector $x$ to a discrete output label, $y = h(x)$. The function is discovered during a training period in which the classifier is exposed to data from a training set $S_{N}$, consisting of $N$ input examples and their labels,\n$$S_{N} = \\{ (x^{(i)}, y^{(i)}), i=1,\u0026hellip;,N \\}.$$\n It\u0026rsquo;s worth paying attention to the notation. The $k$-th component of a vector is indicated using a subscript, $x_{k}$. Subscripts will also be used to indicate a specific piece of information, like a positive training example, $x_+$. The $i$-th member of some collection is indicated by a superscript, e.g. the $i$-th feature vector, $x^{(i)}$. When in doubt, assume you are dealing with a vector.   Imagine you want to build a classifier that can predict whether you will like a brunch dish, based on its ingredients. You might consider a six-item ingredient list:\n ü•î potato ü•ë avocado üçÖ tomato ü•ì bacon üçÑ mushroom ü•´ baked beans  We will represent each brunch dish as a 6-dimensional feature vector, $x^{(i)} \\in \\{0, 1\\}^6$, with $x^{(i)}_{k} = 1$ indicating the presence of the $k$-th ingredient in the $i$-th dish. The label $y^{(i)}=1$ is used to indicate that you like the $i$-th dish (and $y^{(i)}=-1$ to encode the opposite).\nAn example training set $S_5$ containing five example brunch dishes is shown below. Each component of $x$ (in other words, each ingredient $x_k$) is known as a feature.\n   $i$ dish ü•î $x^{(i)}_{1}$ ü•ë $x^{(i)}_{2}$ üçÖ $x^{(i)}_{3}$ ü•ì $x^{(i)}_{4}$ üçÑ $x^{(i)}_{5}$ ü•´ $x^{(i)}_{6}$ $y^{(i)}$      1 avocado sandwich 0 1 0 0 1 0 1    2 huevos rancheros 0 1 1 0 0 1 1    3 bacon and eggs 0 0 0 1 0 0 1    4 english breakfast 1 0 1 1 1 1 -1    5 mushroom chowder 0 0 0 1 1 0 -1     After training our brunch classifier $h_{brunch}$ on the training set, it will learn how to map each input vector to its corresponding label. We could then use it to predict whether we would like something new, like breakfast burritos.\n$$ \\textrm{breakfast burrito} = \\{ü•î, ü•ë, üçÖ, ü•´\\} $$ $$ h_{brunch}(\\{ü•î, ü•ë, üçÖ, ü•´\\}) = h_{brunch}([1, 1, 1, 0, 0, 1]) = \u0026hellip; $$\nMeasuring error Classifiers learn from their mistakes with the help of an algorithm. With each example $(x^{(i)}, y^{(i)})$ considered during training, the algorithm checks to see whether the classifier maps the input to the right label. If $h(x^{(i)}) \\neq y^{(i)}$, the classifier has made a mistake. We define the training error $E_N$ as the average rate of mistakes over the training set,\n$$ E_N(h) = \\frac{1}{N} \\sum_{i=1}^{N} [\\![ h(x^{(i)}) \\neq y^{(i)} ]\\!],$$\nwhere $ [\\![ \\textrm{something} ]\\!] = 1$ if the thing inside is true, and $0$ otherwise. For example, $ [\\![ 2 = 9 ]\\!] = 0$ and $ [\\![ 2 \u0026lt; 9 ]\\!] = 1$. If our brunch classifier gets three of the five training labels wrong, then $E_N(h_{brunch}) = \\frac{3}{5}$.\nKnowing the training error is important, but we are usually more interested in how the classifier would perform in the real world, on data it has not seen before. Since we cannot know how well $h$ would work for every possible feature vector, we settle for knowing the test error $E(h)$, which is computed in the same way as the training error, but with data that have been set aside for this purpose.\nSketching the goal We have talked about the idea of training a classifier to learn from mistakes, but what does that look like? Let\u0026rsquo;s use some sketches to visualize it.\nImagine we are midway through training a linear classifier on a set of $N=5$ two-dimensional feature vectors, $x \\in \\mathbb{R}^2$ (Fig. 1). Their labels, $y \\in \\{-1, 1\\}$ are indicated by the plus/minus symbols. There is also a black line, running through the feature space and dividing it into two halves. This represents our linear classifier.\n  Fig. 1. A linear classifier that can do better, with $E_N(h) = 1/5$.   On the blue half of the feature space, vectors map to $h(x) = 1$, and on the orange half, $h(x) = -1$. We can see that all but one of the training examples have been mapped correctly. Since we have five examples, the training error $E_N(h) = 1/5$.\nNot bad, but looking at the plot, you can see some room for improvement. If we just bump the line, this decision boundary a little bit, we can improve the classifier and achieve zero training error (Fig. 2).\n  Fig. 2. After nudging the decision boundary, we have a better classifier, with no training error.   This, in a nutshell, is what training a classifier looks like. We start off with a function $h$ that is useless, but with each iteration of the algorithm, the decision boundary dividing each label region gets nudged and the function becomes slightly better at its job.\nA mathematical translation If you peer into the black box of a classifier and find out how it \u0026ldquo;learns\u0026rdquo;, you will be unsurprised to find some mathematics. What might surprise you is how little of it you need to know to more fully understand the general problem of classification. In this section we will motivate the use of linear algebra as a language to describe the problem at hand, using it to flesh out the ideas of the previous section.\nThe decision boundary A binary classifier splits the feature space into two, using a decision boundary. Before we can update the classifier, it needs to be described in language that a training algorithm can understand. That is, we need to parameterize the decision boundary. Once we have this, the algorithm can update the decision boundary parameters to improve the classifier.\nIn general, the decision boundary is a function of the inputs. A linear classifier working in a $d$-dimensional feature space has a decision boundary that is a linear combination of the input features,\n$$ x_1 \\theta_1 + x_2 \\theta_2 + \u0026hellip; + x_d \\theta_d + \\theta_0 = x \\cdot \\theta + \\theta_0 = 0 $$\nwhere $\\theta = [\\theta_1, \\theta_2, \u0026hellip;, \\theta_d] \\in \\mathbb{R}^d$ is a $d$-dimensional vector that determines the relative influence of each feature on the classification, and $\\theta_0 \\in \\mathbb{R}$ is a scalar offset.\n Note that the dot in $x \\cdot \\theta$ denotes the dot product of two vectors. Geometrically, this operation is defined by $\\newcommand{\\norm}[1]{|| #1 ||}$\n$$ x \\cdot \\theta = \\norm{x} \\norm{\\theta} \\textrm{cos}\\:\\alpha, $$\nwhere $\\norm{x}$ is the norm of $x$ and $\\alpha$ is the angle between the two vectors. If this looks completely foreign to you, it\u0026rsquo;s probably a good idea to stop here and learn the geometric implications of $x \\cdot \\theta$ before continuing. Make some sketches!\n  To get comfortable with what exactly $\\theta$ means here, let\u0026rsquo;s scale the feature space back to two dimensions and play around with the simplest linear classifier: one whose decision boundary passes through the origin, i.e. $\\theta_0 = 0$ (Fig. 3). In this case, the decision boundary takes the form of a line,\n$$ x_1 \\theta_1 + x_2 \\theta_2 = x \\cdot \\theta = 0. $$\n  Fig. 3. A linear classifier, with decision boundary $x \\cdot \\theta = 0$ going through the origin.   Let\u0026rsquo;s consider the geometry of our situation. This was not mentioned earlier, but by convention, $\\theta = [\\theta_1, \\theta_2]$ is chosen such that it points towards the (blue) positively-labeled feature space, as indicated in the figure. Keep this in mind.\nNow, any vector $x = [x_1, x_2]$ that lies exactly on the decision boundary satisfies $x \\cdot \\theta = 0$. That means $x$ and $\\theta$ are perpendicular to each other, which makes sense. The other implication here is that the classifier has no idea what to do with these inputs: should it be unlucky enough to get them, it will map them to the label $y = h(x) = 0$.\n This means that although we are dealing with a binary classifier whose job is to map inputs to one of two output labels $\\{-1, 1\\}$, it is still technically possible for the classifier to map an input to a third output. This is usually avoided in practice by mapping $h(x) = 0$ to one of the labels.   How about some other options? Say we pick a positively-labeled vector $x = [-1.8, 2.6]$. Since the (smallest) angle between $x$ and $\\theta$ is acute, we know that $x \\cdot \\theta \u0026gt; 0$ (Fig. 4, left). Now try a negatively-labeled one: $x = [-3.1, -1.7]$. This time, the dot product $x \\cdot \\theta \u0026lt; 0$ (Fig. 4, right). We are starting to see something useful here!\n  Fig. 4. Left: inputs that are positively labeled (i.e. $h(x) = 1$) have a positive dot product, i.e. $x \\cdot \\theta \u0026gt; 0$. Right: negatively-labeled inputs have a negative dot product.   If we consider the general form of the classifier and add back the scalar offset, such that the decision boundary looks like $x \\cdot \\theta + \\theta_0 = 0$, the key idea stays the same, e.g. if $x \\cdot \\theta + \\theta_0 \u0026gt; 0$, the classifier assigns $x$ a positive label. In other words, $x$ gets mapped to the sign of the quantity $x \\cdot \\theta + \\theta_0$.\nThe binary linear classifier At last, we are ready for a proper definition. A binary linear classifier $h$ is a function that maps feature vectors $x$ to $h(x) \\in \\{-1, 0, 1\\}$, where $$ h(x) = \\textrm{sign}(\\theta \\cdot x + \\theta_0).$$\nThe search for a good classifier now becomes a matter of finding values for the parameter vector $\\theta$ and offset parameter $\\theta_0,$ such that the classifier output or prediction $h(x^{(i)})$ is equal to $y^{(i)}$ for a decent proportion of the training set. We will talk about how we find these values very soon.\nAlthough we have made use of two-dimensional examples, the same concepts hold in higher dimensions. In general, the decision boundary is a hyperplane of the feature space. All that fancy word means is that for a $d$-dimensional feature space, the decision boundary is an $(d-1)$-dimensional subset of that space. You have already seen that for a two dimensional feature space, i.e. $x \\in \\mathbb{R}^2$, the decision boundary is a line. If we move up another dimension and consider features $x \\in \\mathbb{R}^3$, the decision boundary becomes a plane, as shown below.\n  Fig. 5. Within a three-dimensional feature space, the decision boundary becomes a plane.   Linear separability As it turns out, there is a price to pay for this level of simplicity: linear classifiers of this type are quite constrained. Consider the following two-dimensional dataset (Fig. 6). It is an illustration of XOR, the boolean operation that says you can have either one of these two things $(x_1=1 \\textrm{ or } x_2=1)$, but not both $(x_1=1 \\textrm{ and } x_2=1)$.\n XOR comes up often in life. As an example, let $x_1$ and $x_2$ be items on the dessert menu at a restaurant, i.e., $\\{x_1, x_2 \\} \\in \\{üç®,üç∞,ü•ß,üçÆ\\}.$     Fig. 6. A dataset that is not linearly separable.   No matter how you slice it, there is no way to draw a line through these training examples to perfectly group them by label. This is an example of a dataset that is not linearly separable. More formally, the training dataset $S_N = \\{(x^{(i)}, y^{(i)}), i=1,\u0026hellip;, N\\}$ is said to be linearly separable if there exists a parameter vector $\\hat{\\theta}$ and offset vector $\\hat{\\theta_0}$ such that for all training examples $i=1,\u0026hellip;,N$,\n$$ y^{(i)}(\\hat{\\theta} \\cdot x + \\hat{\\theta_0}) \u0026gt; 0.$$\nTake a moment to understand this expression. Imagine we have a pair of these special values $\\hat{\\theta}$ and $\\hat{\\theta_0}$ for some dataset. If we look at the above inequality for a positive example $x_+$, we know that $(\\hat{\\theta} \\cdot x_+ + \\hat{\\theta_0})$ must be positive for it to hold, since $y_+=1$. Similarly, for a negative example $x_-$, the quantity $(\\hat{\\theta} \\cdot x_- + \\hat{\\theta_0})$ must evaluate to a negative value.\nWhat we can see here is that when $y^{(i)}(\\theta \\cdot x^{(i)} + \\theta_0) \u0026gt; 0$, the label and classifier output for the $i$-th training example $x^{(i)}$ are in agreement. When this equality is not true, the prediction does not match the label and the classifier has made a mistake.\nTeaching the classifier It is finally time to talk about how a classifier learns from experience. Until now there have been many mentions of an \u0026ldquo;algorithm\u0026rdquo;, which is vaguely understood to be used for training the classifier. Here we will introduce the perceptron, a simple and elegant algorithm whose variants have been widely applied to solve all kinds of problems.\nTo train a classifier, an algorithm needs to recognize when the classifier makes a mistake. Recall that the training error for a linear classifier looks like this:\n$$ E_N(h) = \\frac{1}{N} \\sum_{i=1}^{N} [\\![ h(x^{(i)}) \\neq y^{(i)} ]\\!],$$\nwhere $[\\![ h(x^{(i)}) \\neq y^{(i)} ]\\!]$ equals one for a mistake, and zero otherwise. But thanks to our previous discussion, we know precisely how to express a mistake, i.e,\n$$y^{(i)}(\\theta \\cdot x^{(i)} + \\theta_0) \\leq 0.$$\nWith that in mind, let\u0026rsquo;s take a stroll through the perceptron.\nThe perceptron The perceptron algorithm takes a training set $S_N$ input, and outputs the classifier parameters $\\theta$ and $\\theta_0$. The general principle is to find a mistake and then update the parameters to fix the mistake. As long as the training data are linearly separable, doing this for long enough will eventually result in some parameters that do the job.\nIt is typical to initialize $\\theta$ to a $d$-dimensional zero vector (where $d$ is the number of features) and $\\theta_0$ to a scalar zero. For now we will ignore $\\theta_0$ and focus on training a linear classifier whose decision boundary runs through the origin. We begin the proceedings with the following items:\n theta, a $d$-element array of zeros, feature_matrix, a $d \\times N$ feature matrix, with a training example on each row, labels, an array of $N$ labels for each training example.  An incomplete Python (Numpy) implementation of the algorithm looks like this:\ndef incomplete_perceptron(feature_matrix, labels): num_features, num_examples = feature_matrix.shape theta = np.zeros(num_features) for i in range(num_examples): x, y = feature_matrix[i, :], labels[i] # update theta when we have made a mistake if y * np.dot(theta, x) \u0026lt;= 0: theta = theta + y * x return theta  At the update step, the algorithm tests to see whether theta, the current iteration of the classifier computes the wrong training label. When that happens, $\\theta$ is updated by adding $y^{(i)} x^{(i)}$ to it.\nTo see why that should help things, let\u0026rsquo;s consider the scenario after one update, where $\\theta = y^{(i)}x^{(i)}.$ Now imagine if the classifier saw the same training example. If we plugged our updated $\\theta$ value into the \u0026ldquo;mistake detector\u0026rdquo;, we would get\n$$ y^{(i)} (\\theta \\cdot x^{(i)}) = y^{(i)} ((y^{(i)}x^{(i)}) \\cdot x^{(i)}) = x^{(i)} \\cdot x^{(i)} = \\norm{x^{(i)}}^2$$\nNow unless you happen to have a row of zeros inside your feature matrix, the squared norm of $x$ is always greater than zero, and so the mistake has been corrected. We can see that the algorithm has somehow improved the situation.\nNumber of iterations As we go through the training examples, the parameter vector $\\theta$ will change rapidly, sometimes cancelling out the effect of previous examples. It is for this reason that the dataset is typically iterated over multiple times, ideally until the algorithm no longer finds a mistake.\nTo complete the algorithm, we will introduce a new input $T$ that specifies how many times to loop through the dataset, and factor the offset parameter theta_0 into our computation. The last change to make is a practical one: it is tricky to check whether a numerical computation equals an exact value, like zero. To avoid numerical instabilities, we will instead use a tolerance parameter $\\epsilon$, such that if some result $|r| \u0026lt; \\epsilon$, then $r = 0$.\ndef perceptron(feature_matrix, labels, T=1, tolerance=1e-6): num_features, num_examples = feature_matrix.shape theta = np.zeros(num_features) theta_0 = 0 for t in range(T): for i in range(num_examples): x, y = feature_matrix[i, :], labels[i] # update theta, theta_0 when we have made a mistake if y * (np.dot(theta, x) + theta_0) \u0026lt; tolerance: theta = theta + y * x theta_0 = theta_0 + y return theta, theta_0  The offset update It is worth making a quick note about how the update for the offset parameter $\\theta_0$ comes about. Consider a dataset that has been \u0026ldquo;extended\u0026rdquo;, such that $\\theta_{ext} = [\\theta, \\theta_0]$ and $x_{ext} = [x, 1],$ where $x \\in S_N$. If we want to update $\\theta_{ext}$ using our extended training data, we use the same update rule as before,\n$$\\begin{align*} \\theta_{ext} \u0026amp;= \\theta_{ext} + y^{(i)} x_{ext}^{(i)} \\\\\n\\end{align*} $$\nExpanding this out reveals the update for both parameters:\n$$\\begin{align*} \\begin{bmatrix} \\theta\\\\\n\\theta_0 \\end{bmatrix} \u0026amp;= \\begin{bmatrix} \\theta\\\\\n\\theta_0 \\end{bmatrix} \\end{align*} + y^{(i)} \\begin{bmatrix} x^{(i)}\\\\\n1 \\end{bmatrix} $$\nIn other words, handling the extra offset parameter $\\theta_0$ is just a matter of considering slightly different training examples.\nSummary Over the course of this writeup we have peeked behind the curtain and seen that machine learning, for all the hype and buzz, is not something overly mysterious. At heart, machine learning is the practice of identifying patterns in data using some kind of model, with the \u0026ldquo;learning\u0026rdquo; achieved through improving the model parameters.\n","date":1603667013,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603667013,"objectID":"6745bdb837ff693b67ab8ef1feac9b8b","permalink":"https://www.remotelycurious.net/post/ml-doc-01-1-learning-from-data/","publishdate":"2020-10-25T19:03:33-04:00","relpermalink":"/post/ml-doc-01-1-learning-from-data/","section":"post","summary":"How does a computer learn from experience?","tags":["machine-learning","edx","classification","algorithm","perceptron"],"title":"ml.doc (1.1): Learning from data","type":"post"},{"authors":[],"categories":["development","issues.app"],"content":" This writeup is a result of my efforts to learn web app development with Flask. It builds on the codebase from the previous writeup, which you can find here. Any code documented here may change significantly in the future. Be warned!   Today I\u0026rsquo;ll be documenting several structure-related changes that collectively represent a significant change to the codebase. In order of appearance, these changes are as follows:\n switching from Flask-Bootstrap to Bootstrap-Flask (i.e. Bootstrap v3 to v4) relocating several source files for more meaningful project structure implementation of blueprints for better code modularity.  These are not sexy changes, so to sweeten the deal, I\u0026rsquo;ve also gone ahead and cooked up the beginnings of a user interface for the project. You\u0026rsquo;ll get a glimpse of it as I detail the migration of the codebase to Bootstrap-Flask.\nLet\u0026rsquo;s get started!\nTable of Contents  Using better templates  Switching to Bootstrap-Flask The proto-interface   The base template     Project restructure Blueprints  The main blueprint       Summary   Using better templates The first order of business is to make a base template for the issue tracker. By defining page components and using template blocks (e.g., {% block content %}), a base template can make page components available to a child template, such that the derived page can use or modify the base template\u0026rsquo;s content. I will use the base template to hold a navbar, a horizontal component on the top of each app page that contains links to other pages, as well as other non-view-specific information (e.g., number of issues assigned to the logged-in user).\nSwitching to Bootstrap-Flask One of the issues I discovered with Flask-Bootstrap is that the package uses Bootstrap 3. At first I didn\u0026rsquo;t see this as an issue, but the more I wanted to play around with the layout, the more time I was sinking into custom CSS changes and fighting the defaults. It\u0026rsquo;s worth noting that even though I am definitely not an interface designer, nor a master of CSS, I am fussy when it comes to design. By the time I was satisfied with my navbar, more than three hours had passed through a rapid cycle of Google searches, browser element inspection and minute CSS changes. And that\u0026rsquo;s just a single navbar!\nAfter reading so many Stack Overflow posts containing some variant of \u0026ldquo;this is resolved in v4\u0026rdquo;, I pulled the plug on Flask-Bootstrap and replaced it with Bootstrap-Flask, which uses Bootstrap 4. If you are in any doubt about which version to use, take it from me: use v4.\nThe proto-interface The first version of our issue tracker interface can be seen below. At this stage it\u0026rsquo;s really just the navbar with a very plain content page. Most of the what you\u0026rsquo;re looking at is described by a base template, with the content underneath the navbar filled out by each child template. We have four child templates, one for each major component in the app:\n the dashboard, the projects page, the issues page, the message page.    Fig. 1. The proto-interface for the app.   Aside from some links to different application views, the navbar contains some other information. We have a couple of badges: little numerical indicators that hold the number of active issues and unread messages for the user. There\u0026rsquo;s also a user dropdown menu that lists the username and their role. We will save a proper description of the major data entities underlying this project (users, projects, issues, messages, etc.) for when we get to implementing the project\u0026rsquo;s database. That will definitely warrant a separate writeup.\nCurrently, each child template looks almost identical and pretty boring. This is what the dashboard template looks like:\nsrc/templates/dashboard.html {% extends \u0026quot;base.html\u0026quot; %} {% block content %} \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;col\u0026quot;\u0026gt; \u0026lt;h1\u0026gt;Dashboard\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This test content comes from the dashboard template.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Unlike Flask-Bootstrap, Bootstrap-Flask does not come with its own base template, so you have to make one. The next section provides an overview of this project\u0026rsquo;s base template, as well as some important aspects of its design.\nThe base template After leading with the DOCTYPE tag, the base template includes some meta tags in the head element that allow for the view to be responsive, the effects of which will be shown soon. We also have some code that sets the favicon and loads CSS files, including Bootstrap and a custom CSS file for small design tweaks.\nsrc/templates/base.html \u0026raquo; \u0026lt;head\u0026gt; {% block head %} \u0026lt;!-- required meta tags --\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;meta name=\u0026quot;viewport\u0026quot; content=\u0026quot;width=device-width, initial-scale=1, shrink-to-fit=no\u0026quot;\u0026gt; \u0026lt;!-- favicon resources --\u0026gt; \u0026lt;link rel=\u0026quot;shortcut icon\u0026quot; href=\u0026quot;{{ url_for('static', filename='favicon-16.png') }}\u0026quot; type=\u0026quot;image/png\u0026quot;\u0026gt; \u0026lt;link rel=\u0026quot;icon\u0026quot; href=\u0026quot;{{ url_for('static', filename='favicon-16.png') }}\u0026quot; type=\u0026quot;image/png\u0026quot;\u0026gt; {% block styles %} \u0026lt;!-- bootstrap CSS --\u0026gt; {{ bootstrap.load_css() }} \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ url_for('static', filename='custom.css') }}\u0026quot;\u0026gt; {% endblock %} \u0026lt;title\u0026gt;issues.app\u0026lt;/title\u0026gt; {% endblock %}  Most of the remaining code is within the body element and is used to define the navbar. Bootstrap is a mobile-first framework, so it\u0026rsquo;s worth putting a bit of thought into the navbar\u0026rsquo;s layout for different window sizes. After deciding which components to include in the navbar, we can then choose which components to hide or collapse when the display size is small enough.\n A mobile-first design philosophy is geared at making content look good on small displays (e.g., those of phones and tablets), before considering larger displays like laptop screens. This compels you to consider content before everything else, saving your screen real estate for what actually matters.     Fig. 2. A collapsed navbar shows a hamburger menu.   Components can be collapsed by nesting the components within a div.collapse.navbar-collapse element. The .navbar-toggler class is used to bundle collapsed components into a hamburger menu that references the components using the #navbarNavDropdown ID. The navbar-brand element, used to access the dashboard, will always be shown.\n  Fig. 3. Opening up the menu.   src/templates/base.html \u0026raquo; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026quot;navbar navbar-fixed-top navbar-expand-md navbar-light bg-light\u0026quot;\u0026gt; \u0026lt;!-- app brand --\u0026gt; \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;{{ url_for('index') }}\u0026quot;\u0026gt; \u0026lt;img class=\u0026quot;d-inline-block align-top\u0026quot; src=\u0026quot;{{ url_for('static', filename='favicon-32.png') }}\u0026quot; \u0026gt; issues.app \u0026lt;/a\u0026gt; \u0026lt;!-- hamburger menu --\u0026gt; \u0026lt;button class=\u0026quot;navbar-toggler\u0026quot; type=\u0026quot;button\u0026quot; data-toggle=\u0026quot;collapse\u0026quot; data-target=\u0026quot;#navbarNavDropdown\u0026quot; aria-controls=\u0026quot;navbarNavDropdown\u0026quot; aria-expanded=\u0026quot;false\u0026quot; aria-label=\u0026quot;Toggle navigation\u0026quot;\u0026gt; \u0026lt;span class=\u0026quot;navbar-toggler-icon\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;!-- items below collapse into the menu above--\u0026gt; \u0026lt;div class=\u0026quot;collapse navbar-collapse\u0026quot; id=\u0026quot;navbarNavDropdown\u0026quot;\u0026gt; \u0026lt;!-- logged-in user dropdown --\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav ml-auto order-1\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item dropdown\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link dropdown-toggle\u0026quot; href=\u0026quot;#\u0026quot; id=\u0026quot;navbarUserDropdown\u0026quot; role=\u0026quot;button\u0026quot; data-toggle=\u0026quot;dropdown\u0026quot; aria-haspopup=\u0026quot;true\u0026quot; aria-expanded=\u0026quot;false\u0026quot;\u0026gt; \u0026amp;nbsp;{{ user_data['user'] }}\u0026lt;span class=\u0026quot;badge badge-secondary\u0026quot;\u0026gt;{{ user_data['role'] }}\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;caret\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;div class=\u0026quot;dropdown-menu\u0026quot; aria-labelledby=\u0026quot;navbarUserDropdown\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Profile\u0026lt;/a\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Settings\u0026lt;/a\u0026gt; \u0026lt;div class=\u0026quot;dropdown-divider\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;a class=\u0026quot;dropdown-item\u0026quot; href=\u0026quot;#\u0026quot;\u0026gt;Sign out\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;!-- major app sections --\u0026gt; \u0026lt;ul class=\u0026quot;navbar-nav mr-auto order-0\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;nav-item {{ 'active' if is_active['projects'] }}\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link d-flex align-items-center\u0026quot; href=\u0026quot;{{ url_for('projects') }}\u0026quot;\u0026gt; \u0026amp;nbsp;Projects\u0026amp;nbsp; \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item {{ 'active' if is_active['issues'] }}\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link d-flex align-items-center\u0026quot; href=\u0026quot;{{ url_for('issues') }}\u0026quot;\u0026gt; \u0026amp;nbsp;Issues\u0026amp;nbsp;{% if user_data['num_issues'] %}\u0026lt;span class=\u0026quot;badge badge-pill badge-primary\u0026quot;\u0026gt;{{ user_data['num_issues'] }}\u0026lt;/span\u0026gt;{% endif %} \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;nav-item {{ 'active' if is_active['messages'] }}\u0026quot;\u0026gt; \u0026lt;a class=\u0026quot;nav-link d-flex align-items-center\u0026quot; href=\u0026quot;{{ url_for('messages') }}\u0026quot;\u0026gt; \u0026amp;nbsp;Messages\u0026amp;nbsp;{% if user_data['num_messages'] %}\u0026lt;span class=\u0026quot;badge badge-pill badge-primary\u0026quot;\u0026gt;{{ user_data['num_messages'] }}\u0026lt;/span\u0026gt;{% endif %} \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt;  Looking at the code above, you will notice some Jinja statements sprinkled around the place. The statements that populate the navbar user data access a dictionary called user_data, which is supplied to Jinja through each view function. For example, the projects template is rendered within the projects() view function as shown below.\nsrc/main/init.py \u0026raquo; create_app() @app.route('/projects') def projects(): return render_template('projects.html', is_active={'projects': True}, user_data=get_user_data()) def get_user_data(): return { 'user': 'ahadjinicolaou', 'role': 'admin', 'num_issues': 12, 'num_messages': 2}  Although the function get_user_data() is just returning some dummy data here, you can imagine this function being rewritten to say, query a Users table in a database and parse the results to create a proper user data dictionary.\nAnother point worth noting is the use of Flask\u0026rsquo;s url_for() function. Recall that we declare view functions in our code using the app.route decorator. Flask keeps track of the association between each URL rule (e.g. /projects) and its view function using the app instance\u0026rsquo;s URL map. You can inspect the URL map for the application by accessing app.url_map within the main package constructor.\nHere\u0026rsquo;s what it looks like:\nMap([\u0026lt;Rule '/projects' (HEAD, OPTIONS, GET) -\u0026gt; projects\u0026gt;, \u0026lt;Rule '/messages' (HEAD, OPTIONS, GET) -\u0026gt; messages\u0026gt;, \u0026lt;Rule '/issues' (HEAD, OPTIONS, GET) -\u0026gt; issues\u0026gt;, \u0026lt;Rule '/' (HEAD, OPTIONS, GET) -\u0026gt; index\u0026gt;, \u0026lt;Rule '/bootstrap/static/\u0026lt;filename\u0026gt;' (HEAD, OPTIONS, GET) -\u0026gt; bootstrap.static\u0026gt;, \u0026lt;Rule '/static/\u0026lt;filename\u0026gt;' (HEAD, OPTIONS, GET) -\u0026gt; static\u0026gt;])  There\u0026rsquo;s some extra stuff in here that we have yet to discuss, but the main takeaway is that for every URL rule, there is an endpoint that identifies the function Flask should use to handle the associated request. By default, Flask uses the name of the function as the endpoint. We can see that, for instance, a request for /projects will be handled using the projects() function.\nWe will take another look at this URL map after restructuring our code to use blueprints, but before we get to that, we need to make a quick fix.\nProject restructure As I was looking at my project structure, it dawned on me that the location of some files doesn\u0026rsquo;t make a lot of sense. I\u0026rsquo;m looking at issues.py, config.py, and __init__.py, all of which are located in src/main. The first two don\u0026rsquo;t need to be so deep within the project structure \u0026ndash; in fact, they should be in the project root, since they don\u0026rsquo;t rely on any project-specific packages. There are two consequences of moving these two files:\n the FLASK_APP environment variable should now be set to issues.py, the config dictionary within __init__.py should now be imported from config.  Speaking of __init__.py, since it contains the create_app() factory function, this file should be a package constructor for the src package, rather than the main subpackage. Moving this file to the src directory allows us to keep our project subpackages (containing different functionality for the app) all in one place. The src/main folder (empty at this point) can instead be used to keep our view functions and error response functions, which we will get to as we further modularize the codebase.\nMoving __init__.py requires us to make changes to the arguments in the Flask object initializer:\n template_folder='./templates', static_folder='./static'.  We also need to update the factory function import statement in the tests/conftest.py file: from src import create_app.\nAlright, we\u0026rsquo;re finally ready to talk blueprints!\nBlueprints One obvious way to better segment our codebase is to somehow isolate our HTML response functions (stuffed within the create_app() factory function) within their own file. There\u0026rsquo;s a wrinkle in that idea, however: outside of the package constructor, the response functions no longer have access to the app variable, and by extension, the app.route decorator.\nHere\u0026rsquo;s where the Blueprint class can help. A blueprint can be used to store all of these response-serving functions, without being attached to the application instance. All that functionality sits in a dormant state, waiting to be registered with the application. Once registered, the functions get grafted onto the app and the instance finds itself with additional powers, just as nature had intended.\nThe main blueprint After moving the factory function code into src, we were left with an empty src/main folder. We will promptly repurpose this folder to house the main blueprint \u0026ndash; the blueprint that tells Flask how to render all of our major app components. All of our response and error functions will now be kept in a main package constructor file. Note that we have to use the main.route view decorator associated with the main blueprint.\nWe also have to use the main.app_errorhandler decorator to handle our 404 response throughout the whole app. Using the main.errorhandler decorator would tell Flask to run this error function only for routes defined by the main blueprint.\nsrc/main/__init__.py from flask import Blueprint from flask import render_template main = Blueprint('main', __name__) @main.route('/') def index(): return render_template('dashboard.html', is_active={}, user_data=get_user_data()) @main.route('/projects') def projects(): return render_template('projects.html', is_active={'projects': True}, user_data=get_user_data()) @main.route('/issues') def issues(): return render_template('issues.html', is_active={'issues': True}, user_data=get_user_data()) @main.route('/messages') def messages(): return render_template('messages.html', is_active={'messages': True}, user_data=get_user_data()) @main.app_errorhandler(404) def page_not_found(e): return render_template(\u0026quot;404.html\u0026quot;, is_active={}, user_data={}), 404 def get_user_data(): return { 'user': 'ahadjinicolaou', 'role': 'admin', 'num_issues': 12, 'num_messages': 2}  After defining the blueprint, we need to register it within the factory function.\nsrc/__init__.py ... from flask import Blueprint # factory function def create_app(config_name): app = Flask(__name__, template_folder='./templates', static_folder='./static') app.config.from_object(config[config_name]) bootstrap.init_app(app) from src.main import main as main_blueprint app.register_blueprint(main_blueprint) return app  Remember that chatter about Flask\u0026rsquo;s URL map? If we print it out now, you\u0026rsquo;ll see that the endpoints for main_blueprint's URL rules have been updated to include the main. prefix.\nMap([\u0026lt;Rule '/projects' (GET, OPTIONS, HEAD) -\u0026gt; main.projects\u0026gt;, \u0026lt;Rule '/messages' (GET, OPTIONS, HEAD) -\u0026gt; main.messages\u0026gt;, \u0026lt;Rule '/issues' (GET, OPTIONS, HEAD) -\u0026gt; main.issues\u0026gt;, \u0026lt;Rule '/' (GET, OPTIONS, HEAD) -\u0026gt; main.index\u0026gt;, \u0026lt;Rule '/bootstrap/static/\u0026lt;filename\u0026gt;' (GET, OPTIONS, HEAD) -\u0026gt; bootstrap.static\u0026gt;, \u0026lt;Rule '/static/\u0026lt;filename\u0026gt;' (GET, OPTIONS, HEAD) -\u0026gt; static\u0026gt;])  Of course, this means that we have to change the corresponding endpoints referenced in the templates. A call to url_for('index') for example will be replaced by url_for('main.index').\nAfter relaunching the server and making sure we haven\u0026rsquo;t broken anything, we should see\u0026hellip; no difference. Brilliant.\n If you\u0026rsquo;ve cloned the project repository, you can run git checkout cff1a49 to get the current version of the source code.   Summary After a little bit of futzing with the codebase, we have ourselves a highly modular codebase that allows us to cleanly segment presentation code from application logic. It\u0026rsquo;s also nice to have the beginnings of what will hopefully become a clean, functional user interface fit for an issue tracker.\nI\u0026rsquo;m also happier after having moved those three project files to more suitable locations \u0026ndash; frankly, their previous locations were an afterthought that I should have noticed earlier. Better late than never!\n","date":1601073258,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601073258,"objectID":"75fa00db0ac943c7cb3aa1a87f4d64d7","permalink":"https://www.remotelycurious.net/post/issues-app-03-blueprints/","publishdate":"2020-09-25T18:34:18-04:00","relpermalink":"/post/issues-app-03-blueprints/","section":"post","summary":"Now featuring a prototype interface and better project structure!","tags":[],"title":"issues.app (3): Modularity with Blueprints","type":"post"},{"authors":[],"categories":["issues.app","development"],"content":" This writeup is a result of my efforts to learn web app development with Flask. It builds on the codebase from the previous writeup, which you can find here. Any code documented here may change significantly in the future. Be warned!   The last article ended with a quick mention about how Python functions can be assigned to handle browser requests in a Flask application. It\u0026rsquo;s a topic that is definitely worth more of our time. We are going to talk about templates: what they are, how they work, and how they can integrate with Bootstrap to make life easier for developers.\nTable of Contents  View decorators  Static routes Dynamic routes Error handlers   Templates  Jinja templates  Variables and expressions Filters Statements Template inheritance   Using templates       Templates with Bootstrap  Plugging Bootstrap into Flask     Making nicer templates       Summary   View decorators In general, decorators are Python constructs that allow you to inject functions with additional capabilities. Flask provides a number of view decorators that can be used to conveniently enable web-specific functionality, making it easy to get things done with minimal code. What follows is a quick tour of some of the most common view decorators you will find in a Flask application.\nStatic routes We\u0026rsquo;ve already seen one of these. A static route can be implemented with the app.route decorator to handle a browser request for a single URL. Here\u0026rsquo;s what that looks like:\n@app.route('/') def index(): return '\u0026lt;h1\u0026gt;Show me the money!\u0026lt;/h1\u0026gt;'   Officially, functions that respond to requests are called view functions.   Dynamic routes We can write another function that uses a dynamic route to serve a customized greeting to the user, using the name argument. Angle brackets are used in the decorator argument to indicate how the function argument should be parsed from the requested URL.\n@app.route('/greeting/\u0026lt;name\u0026gt;') def greeting(name): return f\u0026quot;\u0026lt;h1\u0026gt;Hi {name.capitalize()}!\u0026lt;/h1\u0026gt;\u0026quot;  After adding this to src/main/__init__.py and running the server, a trip to /greeting/fred would serve you with the following:\n  Fig. 1. A personalized greeting.   Error handlers Sometimes it\u0026rsquo;s nice to provide a customized error page. This can be achieved using the app.errorhandler decorator. The decorated function must have an error object argument. It\u0026rsquo;s good practice to return the matching error code together with the response.\n@app.errorhandler(404) def not_found(e): return \u0026quot;\u0026lt;h1\u0026gt;Looks like I can't find that page...\u0026lt;/h1\u0026gt;\u0026quot;, 404  Templates Handling chunks of web code amid our Python source feels a bit dirty. It\u0026rsquo;s probably not a big deal if our view function is returning a one-line response, but imagine the kind of content that Facebook is serving. We\u0026rsquo;re talking reams of HTML, stitched together from different sources that need to be filtered and processed according to the user\u0026rsquo;s data. Sorting this out with a little string interpolation isn\u0026rsquo;t going to cut it. We need a bigger gun.\nThis is where templates come in. A template is a like a mold that is used to mass produce web pages. The mold is made out of standard HTML elements like body and div and has slots reserved for data that will become available in the future. When the data is ready, a template engine can take a template, fill the data slots, and render the complete page. This allows for presentation logic to be isolated from the rest of the code, simplifying application maintenance and making debugging a bit less painful.\nJinja templates Flask uses a template engine called Jinja2 to render templates with data. Jinja templates are usually just HTML files (although other file formats are supported). They will typically contain HTML as well as variables and expressions that are recognized by Jinja and replaced when rendered.\nWe will now explore some basic Jinja template constructs, with an eye towards making better (or at least more flexible) versions of our greeting functions.\nVariables and expressions Let\u0026rsquo;s say Jinja is told to render the template below using a name variable equal to 'fred'.\n\u0026lt;h1\u0026gt;Hi {{ name }}!\u0026lt;/h1\u0026gt;  The {{ ... }} delimiters indicate an expression that Jinja will replace with some kind of output, which in this case is a string literal. Jinja will output Hi fred! after rendering this template.\nVariables can also be more complex objects like lists and dictionaries. We\u0026rsquo;ll see an example of this very soon when we introduce statements.\nFilters Jinja has filters that can be applied to modify variables using the pipe (|) operator. Below are a few examples of templates with their rendered output:\n   Variable Template Output     name='fred' Hi {{ name | upper }}! Hi FRED!   name='emma' Hi {{ name | capitalize }}! Hi Emma!   name=None Hi {{ name | default('Stranger')}}! Hi Stranger!   price=7.283 That is ${{ price | round(2, 'floor') }}. That is $7.28.     Multiple filters can also be chained together, but keep in mind the order of operations. As a contrived example, consider the effect of {{ name | default('stranger') | upper }} versus that of {{ name | upper | default('stranger') }} when name=None.   Statements Jinja becomes considerably more powerful when using statements to control the specific elements that are rendered. Statements are indicated by {% ... %} delimiters.\nImagine we have some kind of shopping list. We can use Jinja to create a bulleted list of our items with the following code:\n\u0026lt;ul\u0026gt; {% for item in shopping_list %} \u0026lt;li\u0026gt;{{ item }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt;  Now if the shopping list contains [\u0026quot;bread\u0026quot;, \u0026quot;milk\u0026quot;, \u0026quot;eggs\u0026quot;, \u0026quot;toy dinosaur\u0026quot;], Jinja will render it as a nice bulleted list (simulated with Markdown):\n bread milk eggs toy dinosaur  Think about our app for a second. Suppose we want to offer up a VIP version of our greeting to users that know the right URL. We can get fancy with our template and have it render a greeting that is sensitive to the time of day, using Jinja to temporarily store different greetings inside variables.\n{% if hour \u0026gt;= 0 and hour \u0026lt; 12 %} {% set greeting = 'Good morning' %} {% elif hour \u0026gt;= 12 and hour \u0026lt; 17 %} {% set greeting = 'Good afternoon' %} {% else %} {% set greeting = 'Good evening' %} {% endif %} \u0026lt;h1\u0026gt;{{ greeting }}, {{ name | capitalize }}.\u0026lt;/h1\u0026gt;  In this case the template engine would be dealing with three variables:\n name and hour, supplied by the application, and greeting, set within the template.  Template inheritance Before we get our hands on some templates, we should talk about template inheritance. As plain and unexciting as that sounds, you should know that this is the most powerful part of Jinja1. Template inheritance allows you to create a \u0026ldquo;master template\u0026rdquo; that holds all of the common web elements of your site as well as blocks that child templates can either build on or completely replace.\n If you\u0026rsquo;re following the project, note that the templates in this section are just provided to illustrate the concepts. They will not be included in the codebase.   To get a better understanding of what we\u0026rsquo;re talking about, let\u0026rsquo;s use an example pair of templates: one base, one child. Below is base.html.\nbase.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; {% block head %} \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; .important { color: #FF0000; } \u0026lt;/style\u0026gt; \u0026lt;title\u0026gt;{% block title %}{% endblock %} :: ACME LLC\u0026lt;/title\u0026gt; {% endblock %} \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {% block content %}{% endblock %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  It looks like a regular HTML page seasoned with some Jinja statements. The base template defines three blocks: head, title and content. Each of these can be overridden by a derived template, like the one below:\nchild.html {% extends \u0026quot;base.html\u0026quot; %} {% block title %}Goods and Services{% endblock %} {% block head %} {{ super() }} \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; .special { color: #0000FF; } \u0026lt;/style\u0026gt; {% endblock %} {% block content %} \u0026lt;h1\u0026gt;Goods and Services\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Bread\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Milk\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;important\u0026quot;\u0026gt;Eggs\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;special\u0026quot;\u0026gt;Toy dinosaur\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; {% endblock %}  The line that makes it a child template is the very first one. With the {% extends \u0026quot;base.html\u0026quot; %} statement, we are telling Jinja that the current template is inheriting from base.html. When the base and derived templates both contain a nonempty block, the content in the derived block takes precedence.\nNote the use of super() within the head block. This tells Jinja to append the block\u0026rsquo;s content to the corresponding block content in the base template. Without the super() call, the child template would completely replace the base template block and we would lose the important CSS class defined in the base template.\nJinja is capable of a lot more. We will cover more of its features in later articles, but for now let\u0026rsquo;s make some templates and refactor the codebase to make use of them.\nUsing templates First we should designate a folder to keep our templates. This will be src/templates. We are going to make two templates: one for the plain greeting and another for the VIP greeting (we\u0026rsquo;ll leave the 404 and index view functions \u0026ldquo;template-less\u0026rdquo; for now). The plain template is shown below.\nsrc/templates/greeting.html \u0026lt;h1\u0026gt;Hi {{ name | capitalize }}!\u0026lt;/h1\u0026gt;  And here\u0026rsquo;s the fancy one.\nsrc/templates/fancy-greeting.html {# time-sensitive greeting #} {% if hour \u0026gt;= 0 and hour \u0026lt; 12 %} {% set greeting = 'Good morning' %} {% elif hour \u0026gt;= 12 and hour \u0026lt; 17 %} {% set greeting = 'Good afternoon' %} {% else %} {% set greeting = 'Good evening' %} {% endif %} \u0026lt;h1\u0026gt;{{ greeting }}, {{ name | capitalize }}.\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;GreetMaster‚Ñ¢: delivering you the finest of greetings.\u0026lt;/p\u0026gt;  Now we need a way to engage the template engine in our app. This is done using render_template(), which comes from the flask package. Each view function supplies render_template() with the appropriate template filename and any keyword arguments that Jinja needs to populate the corresponding variables in the template.\nsrc/main/init.py # ... from flask import render_template from datetime import datetime def create_app(config_name): # ... @app.route('/greeting/\u0026lt;name\u0026gt;') def greeting(name): return render_template('greeting.html', name=name) @app.route('/fancy-greeting/\u0026lt;name\u0026gt;') def fancy_greeting(name): return render_template('fancy_greeting.html', name=name, hour=datetime.now().hour) @app.errorhandler(404) def not_found(e): return \u0026quot;\u0026lt;h1\u0026gt;Looks like I can't find that page...\u0026lt;/h1\u0026gt;\u0026quot;, 404 return app  Finally, Flask needs to be told where we are keeping the templates (otherwise, Flask will assume they are in a templates folder that sits in the same directory as the app\u0026rsquo;s instantiating file). The create_app() function is changed like this:\nsrc/main/init.py def create_app(config_name): app = Flask(__name__, template_folder='../templates') # ...  Now we can fire up the server and serve ourselves with a magnificent greeting page. Since I\u0026rsquo;m typing this up at ~10 PM, I am treated with an evening salutation.\n  Fig. 3. A GreetMaster‚Ñ¢ greeting.   Templates with Bootstrap Our templates are handy but they\u0026rsquo;re ugly. Fortunately, a bunch of people at Twitter came up with Bootstrap, an open-source front-end framework that can integrate with Flask and style our templates. We can plug it into our app as a Flask extension with minimal fuss. That\u0026rsquo;s a big reason you\u0026rsquo;re reading about it right now.\nPlugging Bootstrap into Flask Adding support for Bootstrap within Flask is easy, thanks to the Flask-Bootstrap extension. Below we\u0026rsquo;ll add flask-bootstrap as a project dependency. Make sure to install it in your virtual environment.\nsetup.py from setuptools import setup, find_packages setup( name='issues', version='0.2', packages=find_packages(), install_requires=[\u0026quot;flask\u0026quot;, \u0026quot;pytest\u0026quot;, \u0026quot;pytest-flask\u0026quot;, \u0026quot;flask-bootstrap\u0026quot;], )  Bootstrap can now be installed as an app extension using the init_app() instance method within the main package constructor.\nsrc/main/init.py # ... from flask import Flask from flask_bootstrap import Bootstrap bootstrap = Bootstrap() def create_app(config_name): app = Flask(__name__, template_folder='../templates') app.config.from_object(config[config_name]) bootstrap.init_app(app) # ...  It turns out that all approved Flask extensions will implement the init_app() method. The major upshot of this (application factory) pattern is to allow multiple instances of our application to use a single extension instance. That\u0026rsquo;s good news for people like us who are interested in using a test framework during development.\nMaking nicer templates With the help of Bootstrap, we are going to drag our templates out of the 90s and into the modern age. This is done by having our templates inherit from Flask-Bootstrap\u0026rsquo;s base template. Let\u0026rsquo;s see how this works with our fancy greeting template.\nsrc/templates/fancy_greeting.html {% extends \u0026quot;bootstrap/base.html\u0026quot; %} {# time-sensitive greeting #} {% if hour \u0026gt;= 0 and hour \u0026lt; 12 %} {% set greeting = 'Good morning' %} {% elif hour \u0026gt;= 12 and hour \u0026lt; 17 %} {% set greeting = 'Good afternoon' %} {% else %} {% set greeting = 'Good evening' %} {% endif %} {% block title %}GreetMaster{% endblock %} {% block content %} \u0026lt;div class=\u0026quot;jumbotron jumbotron-fluid\u0026quot;\u0026gt; \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;h1 class=\u0026quot;display-4\u0026quot;\u0026gt;{{ greeting }}, {{ name | capitalize }}.\u0026lt;/h1\u0026gt; \u0026lt;p class=\u0026quot;lead\u0026quot;\u0026gt;GreetMaster‚Ñ¢: delivering you the finest of greetings.\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; {% endblock %}  Flask-Bootstrap\u0026rsquo;s base template provides access to all of Bootstrap\u0026rsquo;s gadgets, like the jumbotron. If you pull back the curtain and take a look at the base template, you\u0026rsquo;ll see that Bootstrap\u0026rsquo;s files are sourced within the template blocks. After relaunching the server and visiting localhost/fancy-greeting/fred, we will now be greeted with a much nicer page.\n  Fig. 4. Our GreetMaster‚Ñ¢ greeting, spruced up with Bootstrap.   Alright, fine. It\u0026rsquo;s still pretty plain. But moving away from Times New Roman has to count for something! Take it as one small step towards a modern interface for our app, which we will build up to as we move through the series.\n If you\u0026rsquo;ve cloned the project repository, you can run git checkout ff8887e to get the current version of the source code.   Summary At this stage you might already appreciate the convenience that templates have to offer us. If not, then that\u0026rsquo;s entirely understandable. After all, we have been putting together some pretty simple pages up until now. Their convenience will be better appreciated once we start sinking our teeth into the prototype interface for the app, which I hope to cover in the next article.\n  Don\u0026rsquo;t take it from me. The developers say it right here in their documentation! \u0026#x21a9;\u0026#xfe0e;\n   ","date":1600042872,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600042872,"objectID":"a8521c67cf761f04aceddc47de3f92b8","permalink":"https://www.remotelycurious.net/post/issues-app-02-templates/","publishdate":"2020-09-13T20:21:12-04:00","relpermalink":"/post/issues-app-02-templates/","section":"post","summary":"A step towards developing interfaces that don't remind you of Geocities.","tags":["flask","python","templates","bootstrap","jinja"],"title":"issues.app (2): Making templates with Bootstrap","type":"post"},{"authors":[],"categories":["issues.app","development"],"content":"My biggest regret is not studying software design as an undergraduate.\nAlthough I\u0026rsquo;ve been writing code for more than a decade, most of the code behind my programs tends to be stuffed into one or two files. This is fine when the programs are small, but a few months ago I had to fix a bug in one of my more complicated apps, which allows a user to load an audio file and manually annotate speech through a graphical interface. Having forgotten entirely about how my app is structured, I had no choice but to trace through the 3300+ lines of code just to reorient myself, before making what turned out to be a simple change. I have since decided that investing time into becoming a good software engineer will pay massive dividends and do wonders for my future sanity.\nThis is the start of what will become a series about web app development using Flask and Pytest. After some research, I singled out these frameworks because they are extensible, well-designed and don\u0026rsquo;t require loads of boilerplate code, which gets in the way of understanding. My main drive is to learn more about application architecture and test-driven development. Along the way I will distill what I learn into this guide, so that it can help other software engineering novices who have similar goals and working knowledge.\n Speaking of knowledge, you should be comfortable with Python to get the most out of this guide. You should also be familiar with relational databases, client-server interactions, and the basics of web development (e.g., writing simple pages in HTTP/CSS/JavaScript).   Table of Contents  Resources Overview Codebase  Project structure Configuration   Protecting your cookies   Application     Test code       Execution  Virtual environment     Environment variables Launching the app Running some tests   Test-driven development  Handling route requests       Summary   Resources I\u0026rsquo;m not a coding novice but there are a lot of uncharted waters here. Throughout the writeup I\u0026rsquo;ll reference docpages from both Flask and Pytest as they are well presented and unusually helpful for those getting started. Aside from the documentation and the odd forum post, my primary resources are these two excellent books:\n  Flask Web Development by Miguel Grinberg,  Python Testing with Pytest by Brian Okken.  Let\u0026rsquo;s get this show started.\nOverview My target application is a fully operational issue tracker (see here for a slick tour through an established product). Sure, it\u0026rsquo;s not the most exciting idea, but getting an app like this up and running calls for a lot of design decisions. There\u0026rsquo;s also enough complexity to make test-driven development worth the effort. To get a feel for what we\u0026rsquo;re talking about, consider just two aspects of the final product:\n a clean and functional user interface, data storage to keep track of users, issues, projects, and their relationships.  The implementation of each of these will heavily depend on how we want to use the issue tracker. We also want some way to authenticate users and securely handle their passwords. Basic account management (e.g. validating new accounts, resetting passwords) will be handled by email. Each of these aspects will be the topic of a separate writeup that builds on the codebase from the previous writeup.\nCodebase It\u0026rsquo;s now time to introduce the initial codebase. The rest of this article goes over the details of how it works as well as the rationale behind its structure.\n If you\u0026rsquo;re looking for a good IDE, I highly recommend Visual Studio Code. It\u0026rsquo;s free, widely supported by an extensive list of add-ons, and easy to work with. It is truly a thing of beauty.   Project structure Our starting codebase is held in the root directory issues-project (Fig. 1). Inside we have the src/main folder, containing three Python files that comprise our app\u0026rsquo;s source code. The tests folder on the same level holds code that will be used to test the application. We also have setup.py, which will be invoked to setup the virtual environment.\n  Fig. 1. Directory listing for issues-project.   There are of course many ways to structure a project. This particular layout allows us to play nice with Pytest and build on the codebase without too much difficulty, but there are other advantages that you can read about in this comprehensive post. As the application grows I will likely bundle unit tests and functional tests into separate folders, but for now this structure will do just fine.\nConfiguration Most large applications need some configuration. Each instance of a Flask application comes with a config attribute that can be modified as if it were a dictionary:\napp = Flask(__name__) app.config['TESTING'] = True  A few config values that we use are listed below:\n SECRET_KEY, used to encrypt session cookies (discussed later), DEBUG, toggles debug mode, which shows an interactive debugger for unhandled exceptions and reloads the development server for code changes, TESTING, toggles testing mode, which tells the app to allow exceptions to propagate, such that they can be handled by a testing framework.  The configuration file is shown below. We have three different configuration structures: one for development, another for testing, and yet another for production. This is useful because often a developer will want to use separate resources for each of these activities. You probably don\u0026rsquo;t want to test CRUD operations on your production database!\nEach configuration inherits from the base Config class, which contains settings that are shared across all configuration types. The secret key is assumed to be stored as an environment variable.\nsrc/main/config.py import os class Config: SECRET_KEY = os.environ.get('SECRET_KEY') class DevelopmentConfig(Config): DEBUG = True class TestingConfig(Config): TESTING = True class ProductionConfig(Config): PLACEHOLDER = True config = { 'development': DevelopmentConfig, 'testing': TestingConfig, 'production': ProductionConfig, 'default': DevelopmentConfig }  We can now use the global config dictionary to easily configure an instance of our application to suit our purpose, whether it be for testing or development:\napp = Flask(__name__) app.config.from_object(config['testing'])  Protecting your cookies It\u0026rsquo;s worth talking a bit more about that secret key and how it affects the user session. Most web applications need to maintain some kind of state with each user without having to dive into (slower) persistent storage. While handling an HTTP request, Flask makes the user session available to the application using the session object. This allows the application to keep track of information across multiple requests using key-value pairs called cookies. We will see how these can be useful later when we start to use them.\nFor now, just know that Flask will not allow you to use user sessions without defining the secret key. This key should be a long string of text that is not easily guessable and sufficiently random. Flask will use this key to cryptographically sign each cookie, such that a bad actor cannot impersonate you (or the application server) by forging your signature.\n Do not store secrets in cookies. Although your signature cannot be (easily) forged, the cookie payload can be very easily decrypted.    Make sure that your secrets (including things like API keys) are securely stored outside of source code. Never commit your secrets to version control!   Application Here we have our application code. If you\u0026rsquo;re looking at this code and thinking there\u0026rsquo;s something missing, well\u0026hellip; alright. It\u0026rsquo;s quite spartan. What we do have in our package constructor (__init__.py) is a factory function. We can use create_app() to create multiple instances of our app and import different configuration sets for each one using app.config.from_object(). This is great for unit testing, as you will soon see.\nsrc/main/__init__.py from flask import Flask from src.main.config import config def create_app(config_name): app = Flask(__name__) app.config.from_object(config[config_name]) return app  The issues.py file is used to instantiate the application. It first looks for the ISSUES_CONFIG environment variable to see which configuration to use, but if that fails, the application is configured with the default (development) settings.\nNote that the create_app() function has significance to Flask\u0026rsquo;s command line utility, which we will use to launch the app. We will discuss this shortly.\nsrc/main/issues.py import os from . import create_app app = create_app(os.getenv('ISSUES_CONFIG') or 'default')  And there we have it. That\u0026rsquo;s the app. Take a moment to appreciate just how lean it is. It won\u0026rsquo;t always be this way!\nTest code We now turn our attention to Pytest and what it will do for us. Taking a look at test_suite.py, we find a rag-tag collection of unit tests. The first test is not particularly useful, but Pytest doesn\u0026rsquo;t care. All it cares about is whether the logic after any assert keyword evaluates to True. If it doesn\u0026rsquo;t, any remaining code in that function is skipped, the function is failed, and Pytest moves on to the next function. If all assertions in the test function are true, the function is passed.\n If you have used other testing frameworks you will appreciate that this is an incredibly beautiful programming construct. You don\u0026rsquo;t need to use things like assertLess(a, b): just write assert a \u0026lt; b.   tests/test_suite.py def test_sanity(): assert 1 + 1 == 2 def test_config(app): assert app.config['TESTING'] def test_response(client): response = client.get('/') assert response.status_code == 200  The remaining two test functions have arguments that sound more relevant. Where do app and client come from? That brings us to our next file.\nWithin the conftest.py file, Pytest expects to find fixtures. These are functions that can be used to prepare something (data, initialization, teardown, etc.) for a test function. In the code below, the pytest.fixture decorator is used to tell Pytest that the function app() is a fixture. Now Pytest knows to run the function whenever it encounters app in the argument list of a test function. The test_config() function in our test suite, for example, gets a fresh instance of our application that has been configured for testing.\ntests/conftest.py from src.main import create_app import pytest @pytest.fixture def app(): # initializes the app with the testing config app = create_app('testing') return app  Note that there is another fixture called client that hasn\u0026rsquo;t been defined. This fixture is automatically made available to us courtesy of the pyflask-test package (installed in our upcoming virtual environment), which looks for an app fixture and uses it to create a test client. We will use the test client to generate browser requests and see whether we are getting back an expected response from our application.\nExecution Now that we have introduced the codebase, it\u0026rsquo;s time to fire it up. We will run issues within a virtual environment that is managed by Miniconda, a lightweight version of the Anaconda package management system.\nVirtual environment We\u0026rsquo;ll go ahead and use Miniconda to create our Python 3.7 environment. Once it\u0026rsquo;s ready, activate and use pip to install our requisite packages. Don\u0026rsquo;t forget that trailing period.\nROOTDIR\u0026gt; conda create -n issues python=3.7 ROOTDIR\u0026gt; conda activate issues (issues) ROOTDIR\u0026gt; pip install -e .  When invoked by the command above, pip will search the current directory for the setup.py file, which includes a list of dependencies needed for issues to run properly. Each package listed in install_requires will be installed into the virtual environment.\nsetup.py from setuptools import setup, find_packages setup( name='issues', version='0.1', packages=find_packages(), install_requires=[\u0026quot;flask\u0026quot;, \u0026quot;pytest\u0026quot;, \u0026quot;pytest-flask\u0026quot;], )  What about that -e? Running pip install with the editable option installs a link within the virtual environment to each local package discovered by find_packages() (i.e., main). One of the major benefits of installing our project packages in this way is that our test files can now import them without resorting to hacky system path workarounds. Even better, the editable option means that we can continue to change the source code without having to reinstall the packages.\n At first glance importing a package from a neighboring directory doesn\u0026rsquo;t seem to be such a big problem, but take a look at the age of this Stack Overflow post. People have been dealing with this issue for a very long time\u0026hellip;   Environment variables Remember that we need to set up a couple of environment variables. The syntax used to do this will vary depending on your shell (see this link for some examples). I\u0026rsquo;m using Visual Studio Code on Windows, whose terminal uses PowerShell. Note that your secret key should be more complex than this random headline I took from the New York Times.\n$env:FLASK_APP='src/main/issues.py' $env:ISSUES_CONFIG='development' $env:SECRET_KEY='Are you overpraising your child?'  There\u0026rsquo;s a variable here that has not yet been introduced to us. As you might suspect, FLASK_APP holds the location of our app. We\u0026rsquo;ll see how Flask uses this variable in the next section.\nLaunching the app Once installed inside the virtual environment, Flask gives us access to flask, a command line utility. Entering flask run will first query the FLASK_APP variable to discover our application. Since we have specified a path to a Python file, Flask will look for the create_app() factory function in this file and use it to instantiate the application. Flask will then start up a development server and host the app on http://localhost:5000/. You can find other ways to configure FLASK_APP in this writeup.\nIf you visit the server right now, you will be greeted with a 404 Not Found error. That\u0026rsquo;s expected, since we haven\u0026rsquo;t yet told Flask how to handle any request. We\u0026rsquo;ll get to that shortly but for now let\u0026rsquo;s kill the server and see how to run our test suite.\nRunning some tests We are going to invoke Pytest through pytest-flask, which gives us access to the test client, as described earlier. We can run the test suite with this command:\n(issues) ROOTDIR\u0026gt; py.test  Pytest will now go off and search through any test code (i.e. files that look like test_*.py or *_test.py) within your current directory and all subdirectories. Test functions should start with \u0026ldquo;test\u0026rdquo;, like test_response().\nRunning py.test results in a big chunk of text that starts with the following:\n============================= test session starts ============================= platform win32 -- Python 3.7.7, pytest-6.0.1, py-1.9.0, pluggy-0.13.1 plugins: flask-1.0.0 collected 3 items tests\\test_suite.py ..F  The last line tells the story: Pytest found three tests in test_suite.py, of which two tests passed (indicated with a .) and one test failed (F).\nAt the end of the test output, we see the following:\n=========================== short test summary info =========================== FAILED tests/test_suite.py::test_response - AssertionError: assert 404 == 200 ========================= 1 failed, 2 passed in 0.08s =========================  Seems like test_response() failed. Let\u0026rsquo;s take another look at the function:\ndef test_response(client): response = client.get('/') assert response.status_code == 200  Pytest is telling us that after our test client made a GET request for the server\u0026rsquo;s root URL, the server did not return with a successful (200 OK) response. We were expecting this since the server gave our browser a 404 Not Found response earlier. Since the returned status code was not equal to 200, the assertion failed and caused our test function to fail.\nTest-driven development We have now set ourselves up to do some test-driven development. Under this methodology, each new feature in our application begins life as a test. The goal is then to implement the feature by writing as little code as possible so as to pass the test. This extremely short development cycle of writing and passing tests is repeated many times until you have yourself an application.\nOur first \u0026ldquo;feature\u0026rdquo; is very simple: deliver a successful response to the client that requests the root URL.\nHandling route requests While the web server is running, it passes all received requests to app, the Flask application instance. The app needs to know how to respond to each requested URL. More specifically, Flask needs to know what function to use to create the response. This is achieved using routes, which associate a URL with a response function. We can use the app.route decorator to specify a route for the root URL:\n@app.route('/') def index(): return '\u0026lt;h1\u0026gt;Show me the money!\u0026lt;/h1\u0026gt;'  In this way, the index() function has now been assigned to handle the response for the root URL. We will add this code to the create_app() function within the issues package constructor:\nsrc/main/__init__.py from flask import Flask from src.main.config import config def create_app(config_name): app = Flask(__name__) app.config.from_object(config[config_name]) @app.route('/') def index(): return '\u0026lt;h1\u0026gt;Show me the money!\u0026lt;/h1\u0026gt;' return app  After revising the code and launching the app with flask run, you will find that a trip to the server root no longer results in a 404 Not Found.\n  Fig. 2. Success!   Let\u0026rsquo;s run pytest once more.\n(issues) ROOTDIR\u0026gt; py.test ============================= test session starts ============================= platform win32 -- Python 3.7.7, pytest-6.0.1, py-1.9.0, pluggy-0.13.1 plugins: flask-1.0.0 collected 3 items tests\\test_suite.py ... [100%] ============================== 3 passed in 0.06s ==============================  As expected, we have passed the tests and restored order to the universe.\n If you\u0026rsquo;ve cloned the project repository, you can run git checkout fe2b7ce to get the current version of the source code.   Summary That concludes the initialization of the issue tracker project. Although it takes a bit more work to distribute a Flask application over several source files, this modular design should allow for a more streamlined development and testing experience.\nThere is a lot of code between what we have and a working issue tracker. In the next article I\u0026rsquo;ll create a basic user interface for the app and motivate the use of templates, which allow for the clean separation of presentation logic and application data.\n","date":1598815718,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598815718,"objectID":"2cae43aa8d382902aabb3067f6cf57e0","permalink":"https://www.remotelycurious.net/post/issues-app-01-intro/","publishdate":"2020-08-30T15:28:38-04:00","relpermalink":"/post/issues-app-01-intro/","section":"post","summary":"The beginning of my journey into the world of web app development.","tags":["flask","python","pytest","TDD"],"title":"issues.app (1): Getting started with Flask and Pytest","type":"post"},{"authors":["AE Hadjinicolaou","P Werginz","J-I Lee","SI Fried"],"categories":[],"content":"","date":1598486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598486400,"objectID":"f33446f567414fb2e920e7478a2bf70b","permalink":"https://www.remotelycurious.net/publication/embc-2020/","publishdate":"2020-09-23T17:16:39-04:00","relpermalink":"/publication/embc-2020/","section":"publication","summary":"High-frequency pulse trains can be used to bias neural activity towards different ganglion cell types, depending on the amplitude (and likely the rate) of pulses.","tags":[],"title":"Differential responses to high-frequency electrical stimulation in brisk-transient and delta retinal ganglion cells","type":"publication"},{"authors":[],"categories":["analysis"],"content":"Lift a rock in your garden and you might find a linear regression model. They are everywhere, working hard to predict all sorts of things, like how much further you can drive with this much fuel in the tank, or how much your house might sell for in your neighborhood. Linear regression models owe their success to their ease-of-use as well as their natural interpretability \u0026ndash; most people would probably find it a lot harder to predict the output of a neural network, compared with that of $y=2x$.\nUnfortunately, it is this ease-of-use and interpretability that make linear regression models especially prone to misuse, even by people who should know better1. Before rushing to apply a model (any model), we need to ask ourselves two questions:\n What does this model assume? Do these assumptions make sense for our data?  As it turns out, the linear regression model makes some pretty strong assumptions that don\u0026rsquo;t always hold up in reality. This writeup takes a look at these assumptions, what happens when they don\u0026rsquo;t hold, and which ones we can bend.\nTable of Contents  Simple linear regression  Meet the residual   Out with the assumptions  Normality Independent errors Normally-distributed errors Homoscedasticity   All too human   Simple linear regression The goal of a linear regression model is to model $k$ response variables, $Y_{1},Y_{2},\u0026hellip;,Y_{k}$ using $p$ predictor variables, $X_{1},X_{2},\u0026hellip;,X_{p}$. In this article we will focus on \u0026ldquo;simple linear regression\u0026rdquo;, or SLR $(k=1)$ to avoid getting bogged down in notation. To model our response $Y$ using $p=3$ predictor variables, for example, we assume a relationship of the form\n$$ Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3}, $$\nwhere $\\beta_{i}$ are predictor coefficients that have been found by the end of the fitting process.\nMost of the core assumptions underlying linear regression have to do with the residuals, which are used to estimate prediction errors. Since they play such an important role in the modeling process, it\u0026rsquo;s worth taking some time to formally introduce them.\nMeet the residual To train a model, you need data. More specifically, you need a set of $N \u0026gt; p$ response observations and predictor measurements, ${(\\hat{y_{i}}, x_{i1},x_{i2},x_{i3} )}_{i=1}^{N}$. Note the little hat sitting on $\\hat{y_i}$. Our model formulation assumes that each of our responses is corrupted by some error $\\epsilon$ such that for our $i$th observation, $\\hat{y_i} = y_i + \\epsilon_i$. The hat indicates that the observations $\\hat{y_i}$ are actually estimates of the true responses $y_i$ that we can never observe.\nOur SLR model relates the predictor measurements to the observations by\n$$ \\hat{y_i} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}x_{i1} + \\hat{\\beta_{2}}x_{i2} + \\hat{\\beta_{3}}x_{i3} + \\epsilon_{i}, $$\nwith our fitting process giving us estimates $\\hat{\\beta_i}$ of the true, hidden coefficients $\\beta_i$. Our model thus consists of a deterministic component (i.e., the equation for $Y$ in terms of the $X_i$s) and a random component, represented by the error $\\epsilon$.\n Unlike the response and the coefficients, the predictor measurements are hatless, meaning that they are assumed to be measured with no error.   Since there is no way to know the true response, we can never know the error terms $\\epsilon_i$. So we estimate them using residuals. Compared directly,\n the error $\\epsilon_i$ is the difference between the measured value and the (unobservable) true value,  $$\\epsilon_i = y_i - y,$$\n the residual $r_i$ is the difference between the measured value and the predicted value computed from the model,  $$r_i = y_i - \\hat{y_i}.$$\nNow that we have some measure of prediction error in the residuals, we can use them to build a loss function that describes the overall model error. Linear regression then works to find the coefficient values that minimize this loss function. The L2-norm loss function $L = \\sum_{i=1}^{N}r_i ^2$ is popular because it punishes outliers and makes finding the optimal coefficients a matter of plugging values into a formula.\nOut with the assumptions Although you will see all sorts of assumptions scattered throughout this article, there are four major ones (each with their own subsection) that rule them all. That is, these four alone are sufficient for linear regression analysis. Some are less demanding than others. Ultimately, you can probably get away with bending all of them in some way (as long as the statisticians aren\u0026rsquo;t looking), with the caveat that your model may become unreliable and therefore unsuitable for inference. Let\u0026rsquo;s see what can happen.\nNormality Our first assumption is inherent in the name of the model: the response is a linear combination of the predictors. This supposedly fundamental assumption is arguably the one that gets overlooked most of the time. Why? In a nutshell, when you\u0026rsquo;re close enough to a curve, it looks like a straight line.\n Note that \u0026ldquo;linear\u0026rdquo; is in the sense of the coefficients, not the predictors. This means that relations like $Y = \\beta X^{2}$ are fine but ones like $Y = \\beta ^{2}X$ are not.     Fig. 1. Any curve can look like a straight line at close range.   There\u0026rsquo;s a reason the \u0026ldquo;flat Earth\u0026rdquo; theory was so compelling before NASA.\nIn practice, we have some wiggle room with this one. As long as our response data $y_{i}$ are far away from any theoretical limit, we can generally draw a straight line through the data and that will be enough for all sorts of applications. CEOs can project their yearly sales, consumers can work out their monthly electricity consumption, and life goes on.\nOn the other hand, if we are looking to describe phenomena more generally, then we need to take the idea of linearity more seriously. Let\u0026rsquo;s say you want to build an SLR model to describe height $H = \\beta_{0} + \\beta_{1}W$ as a function of weight $W$, using data from your coworkers. As long as you have enough coworkers (and enough of them agree to give you that data), you will end up with coefficients $\\hat{\\beta_{i}}$ that capture this relationship for adults that more or less resemble your coworkers. That last point is crucial. If you are a professional wrestler (presumably learning statistical analysis in your own time) and each of your coworkers resembles Thanos, your coefficients will be useless for predicting the height of an average human being. If your coworkers are a regular group of men and women, your coefficients won\u0026rsquo;t help you to predict the height of a child. In general, the more useful you want your model to be, the less likely you\u0026rsquo;ll be using linear regression.\n An important side-effect of the model\u0026rsquo;s formulation has to do with the effect of each predictor on the response. By assuming a response of the form $Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3}$, we are also assuming that the effect of one predictor variable is independent of the others. If this holds, one unit of change in $X_{1}$ will have the same effect on the response, no matter what values the other predictors have. That is a strong assumption!   The bottom line is that under certain circumstances, an SLR model might be enough to describe non-linear phenomena. If you scatter your data and it looks like they will conform to a straight line without excluding too many outliers, it might be all you need. Just be wary about using the model to extrapolate data beyond your current range of responses.\nIndependent errors To assess how good our model is, and to do it correctly, we need the residuals to have properties that are like the actual errors they are supposed to estimate: independent and normally distributed, with zero mean and fixed variance. Each of the remaining core assumptions behind linear regression is right there in that last sentence.\nWhat does it mean for the residuals to be independent? This means that they should not have a relationship with any of the predictors, or each other. When we plot the residuals as a function of a predictor variable (or as a function of time, for time-series data), we don\u0026rsquo;t want to see any kind of pattern. Nothing except some random-looking points centered on zero. Anything else means that the residuals have some kind of structure, suggesting that the model might not be a great fit for the data.\n If the residuals are orders of magnitude smaller than the responses, some residual dependence might be tolerable. But it\u0026rsquo;s usually a good idea to work out how they arise, and how to control for them.   To see what it means when we don\u0026rsquo;t have independent residuals, we\u0026rsquo;ll use the Boston Housing dataset to build a (naive) SLR model of the median house value $V$ based on a single predictor, the mean number of rooms in a house $RM$, related by $V = \\beta_0 + \\beta_1 RM$. We fit our model and sure enough, the more rooms in your house, the greater its predicted value (Fig. 2, left panel). No surprises there.\n  Fig. 2. Median house value $V$ ($1,000s) regressed onto mean room number $RM$ for the Boston Housing dataset. Left: Scatterplot of $V$ against $RM$ with a linear fit (red trace; 95% CI). Right: the corresponding residual plot, with a lowess smoother fit indicated by the orange trace. Data entries whose observations appeared to be capped at the maximum value ($50,000) were excluded from the analysis.   Taking a look at the residual plot in Fig. 2B (right panel), we see that the residuals start off with a positive bias, sagging in the middle of our response range, before increasing again for large room counts. We are underestimating value for houses that don\u0026rsquo;t have an \u0026ldquo;average\u0026rdquo; number of rooms.\nThis residual plot is telling us that our model\u0026rsquo;s deterministic component (i.e., the formula $V = \\beta_0 + \\beta_1 RM$) is missing something important. But before we try adding other predictors, let\u0026rsquo;s make a small change to our single predictor and use its square $RM^2$, as suggested by the authors of the study that initially made use of this dataset2. This cheap modification gets us a slightly better r-squared value (from 0.47 to 0.50) as well as a residual plot that bends a bit closer to zero (Fig. 3). Transforming the predictors (or the response) can improve the distribution of our residuals and the model\u0026rsquo;s fit quality.\n  Fig. 3. Median house value $V$ ($1,000s) regressed onto the square of mean room number $RM^2$ for the Boston Housing dataset.   Of course, it\u0026rsquo;s unlikely that we can model something as complex as house value with a single predictor. By including two more predictors (house age and per-capita crime), we easily improve the model fit ($R^2=0.65$) and our residuals tend closer to zero. Generally, additional predictors should be considered if (a) they are informative for the response variable, and (b) they are (at most) weakly correlated with any of the existing predictors.\nCorrelation, whether among the residuals or among the predictors, can cause all sorts of problems in regression analysis. As an extreme example, consider what would happen if we fit a model of house value with two perfectly correlated predictors, $RM$ and $RM^2$. Compared with the model that only includes $RM^2$, we net ourselves an artificial boost in $R^2$ (from 0.50 to 0.53) and our $RM^2$ coefficient estimate ends up being an order of magnitude larger (from 0.67 to 2.23). Not only do we not gain any meaningful insight with our extra predictor, we actually lose insight \u0026ndash; we have made it harder to understand the true effect of room count on house value.\nLinear regression has a couple more things to say about the distribution of our residuals.\nNormally-distributed errors The errors (and the residuals) should not only have a mean of zero, they should also be normally distributed with constant variance $\\sigma^2$. We can write this as\n$$ \\epsilon_i \\sim \\textrm{Normal}(0,\\sigma^2). $$\nIf the errors are not normally distributed, you can still go ahead and compute coefficients, but your measures of uncertainty and significance testing may be compromised if you don\u0026rsquo;t have enough observations. For instance, the standard error terms for the predictor coefficients and the model itself, and by extension, their associated confidence intervals, are all computed under the assumption of residual normality. If you do find evidence of non-normality (preferrably through statistical measures like the Kolmogorov-Smirnov test, rather than by visual inspection), but you\u0026rsquo;ve decided that it\u0026rsquo;s acceptable, it might be best to use wider confidence intervals to indicate this additional uncertainty, documenting your rationale.\n How much non-normality is acceptable? That\u0026rsquo;s a tricky question that usually depends on your experience. Probably best to ask a statistician!   Your ears might have detected a loophole earlier, in that we might not need normally-distributed residuals if our observation count is high enough. Thanks to the central limit theorem, it turns out that with a moderate observation count (let\u0026rsquo;s say $N\u0026gt;20$), linear regression will be perfectly capable of handling your non-normal response data3. The specific number of observations you need will vary depending on whether your response variable is \u0026ldquo;well-behaved\u0026rdquo; or not. If you are dealing with extremely skewed response distributions or large outlier counts, for instance, you will likely need (many) more observations.\nHomoscedasticity In the last section we described the errors as being normally distributed, but we didn\u0026rsquo;t talk about their variance. When we write $ \\epsilon_i \\sim \\textrm{Normal}(0,\\sigma^2),$ we are saying that the errors are identically distributed for every observation $i$, as if each is being drawn from the same normal distribution with zero mean and variance $\\sigma^2$. The errors are said to be homoscedastic.\n(Which is a bit of a mouthful. I\u0026rsquo;d rather just say they have constant variance.)\nWe can test for constant variance using most modern statistical libraries (e.g. statsmodels) but a quick visual indication can be found in the residual plots. If the spread of residuals appears to vary with a given predictor, you should probably run a test to confirm its severity and whether you can tolerate it in your analysis. Too much variability will compromise any measures of uncertainty or significance.\nAll too human So with all these statistical landmines, why are linear regression models so pervasive? Probably because we can understand them. It is difficult to wrap our minds around nonlinear phenomena because the mental models we use to make sense of our world tend to be linear!\n  Porter, Misuse of correlation and regression in three medical journals. Journal of the Royal Society of Medicine (1999). \u0026#x21a9;\u0026#xfe0e;\n Harrison Jr \u0026amp; Rubinfeld, Hedonic housing prices and the demand for clean air. Journal of Environmental Economics and Management (1978). \u0026#x21a9;\u0026#xfe0e;\n Lumley et al., The importance of the normality assumption in large public health datasets. Annual Reviews (2002) \u0026#x21a9;\u0026#xfe0e;\n   ","date":1594605990,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594605990,"objectID":"ca8c064d664f00a34bed5ff67dc17fd2","permalink":"https://www.remotelycurious.net/post/beware-linear-regression/","publishdate":"2020-07-12T22:06:30-04:00","relpermalink":"/post/beware-linear-regression/","section":"post","summary":"Look left and right before using these naive creatures.","tags":["machine-learning","statistics"],"title":"Beware those bearing linear regression models","type":"post"},{"authors":[],"categories":[],"content":"","date":1591802049,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591802049,"objectID":"d4a2008e8b08409900be2732014ee5b2","permalink":"https://www.remotelycurious.net/project/intent-decoder/","publishdate":"2020-06-10T11:14:09-04:00","relpermalink":"/project/intent-decoder/","section":"project","summary":"Modeling speech intent from spoken words and decoding intent from brain activity","tags":[],"title":"Intent Decoder","type":"project"},{"authors":null,"categories":["sysadmin"],"content":"It turns out that the journey to setting up a homelab is filled with trapdoors and snake pits.\nThis writeup is largely for documentation purposes \u0026ndash; it\u0026rsquo;s written as a note to my future self who might look to recreate this setup and wonder why certain design decisions were made. My goal is to avoid having to rediscover all of the little hazards that can (and did) result in hours of frustration. That said, my hope is that other people with similar goals can learn from my experience and save themselves from navigating seas of browser tabs in search of enlightenment.\nBy the time my homelab took shape, I had made use of all sorts of resources on the topic. One of the best belongs to Dan Ford, whose excellent homelab writeup series really helped me to get started. The documentation for Proxmox and pfSense was also useful. Aside from these, there were also many valuable snippets of information, forum posts and docpages scattered throughout the internet, which have been cited where appropriate.\nTable of Contents  Objectives Requirements  Hardware Hypervisor Network   Installation  Installing Proxmox  File system Network configuration   Configuring Proxmox  Enabling software updates Uploading ISO images Configuring the virtual network   Installing pfSense  Configuring pfSense   Creating the internal network  Restricting access     Summary   Objectives There are a lot of reasons you might want to build a homelab. Many of them have to do with learning something. My short-term goal is to learn system administration (things like configuring firewalls and networks, managing security policy, etc) but eventually I want to learn more about network intrusion detection. I\u0026rsquo;d be curious to see if I could break into my own network \u0026ndash; and what that would look like from the perspective of a sysadmin.\nRequirements A homelab can take many forms, from an array of physical computers mounted on racks, to a book-sized unit hosting a virtualized computer network. In this section I discuss the major constraints and design decisions that guided my approach.\nHardware Since I like quiet and despise both heat and clutter, the first major constraint was that this homelab needed to be virtual. This means the homelab is going to be implemented by a bare-metal hypervisor1, on a host computer with a low noise, power, and physical profile. In the end I went with the Protectli FW6B. It\u0026rsquo;s a silent, well-built unit that comes with a dual-core i3-7100U and 6x Intel Gigabit NICs. I opted to load it with 2x8 GiB of DDR4 RAM and 480 GiB of mSATA storage. This is definitely overkill for a bunch of lightweight VMs, but I\u0026rsquo;ll be putting this little box to good use in future projects.\n Whatever you do, make sure that your host CPU supports virtualization!    According to people who know better, Intel NICs seem to better support virtualization, compared with those from other manufacturers.   Hypervisor After a couple hours of internet research, I decided to run with Proxmox as my hypervisor. People also seem to be pretty happy with ESXi, but my decision largely came down to favoring an unrestricted, open-source solution. I\u0026rsquo;m definitely not a seasoned practitioner, so it\u0026rsquo;s unlikely that I would really be able to appreciate the difference between the two products right now.\nNetwork To start with, having some virtual machines running on an internal network, isolated from the home network by a firewall, sounds like a good idea. pfSense is a well-regarded firewall whose documentation specifically includes guidance on running it as a VM in Proxmox, which is exactly what I want to do. It also can be configured as an intrusion detection/prevention system by way of add-on packages like Suricata and Snort, something I\u0026rsquo;m keen to play around with in the future.\nAlthough I\u0026rsquo;m generally comfortable with vanilla home networking, there\u0026rsquo;s a lot of uncharted territory for me in this project. To limit what could go wrong, I will keep things simple and just focus on getting a basic system up-and-running. This means leaving things like VLAN configuration and SSH access for another homelab iteration.\nThe schematic for the eventual homelab is shown below:\n  Fig. 1. Homelab schematic, with two virtual switches (vmbrx) and three VMs.   Installation Before beginning, you should have the following:\n $\\geq$8 GB USB flash drive Rufus installer (rufus-3.10.exe) Proxmox VE ISO image (proxmox-ve_6.2-1.iso) pfSense ISO image (pfSense-CE-2.4.5-RELEASE-amd64.iso) Linux ISO image (CentOS-8.1.1911-x86_64-dvd1.iso)   Rufus will be used to wipe and format the USB drive as a bootable installation drive2, so please make sure it\u0026rsquo;s not holding anything of value! Once you\u0026rsquo;ve selected the USB drive under Device and the Proxmox ISO image under Boot selection, go ahead and click Start. You might get a couple of prompts:\n \u0026ldquo;Download a newer version of GRUB?\u0026rdquo; ‚Üí No \u0026ldquo;Write as an ISO image or DD image?\u0026rdquo; ‚Üí Write in DD Image mode  Once the disk is written, plug it into your homelab host and turn it on. Immediately hold down ESC or DEL and let go once you\u0026rsquo;ve entered the BIOS.\n At this point, you should probably enable UEFI mode. Most operating systems these days support UEFI, which allows for things like using a mouse in the installation GUI. The only reason to use legacy mode is for compatibility with ancient OS installation media.    While we\u0026rsquo;re here, make sure that the relevant virtualization setting (Intel VT, AMD-V, SVM, etc) is enabled.   Within the BIOS, find the boot section and either reorder the device list such that your USB drive comes first, or if there\u0026rsquo;s an option to immediately boot from a selected device, use that to boot from the drive. Selecting Install Proxmox VE from the menu that pops up will launch the installatoon process.\nInstalling Proxmox While going through the installation process, you will have to make some important decisions. The first of these concerns what file system to use on the host.\nFile system If we ignore Ext3, we have three choices: Ext4, XFS, and ZFS. The default file system, Ext4, was designed to be backwards-compatible with older file systems. It\u0026rsquo;s known for stability, which is probably the reason why it\u0026rsquo;s the default file system on most Linux distributions. XFS is another mature solution that is particularly well-suited for servers that deal with many large (exbibytes) files.\n ZFS is a next-generation file system that was designed to eliminate many issues found in legacy file systems. ZFS is probably the way to go for someone who knows what they\u0026rsquo;re doing (and doesn\u0026rsquo;t need support for enormous files) \u0026ndash; you get great performance, configuration flexibility, and access to enterprise-level features, in return for a larger memory footprint and a bit more configuration.\nSince I\u0026rsquo;m just learning the ropes and don\u0026rsquo;t really need advanced features and capabilities, I left Proxmox with Ext4 as the default choice. You would only see the option to change this by clicking Options next to the Target Harddisk dropdown during the installation, so keep this in mind if you want to choose a different file system3.\nNetwork configuration Proxmox will eventually ask you to confirm your network configuration. The IP address here will be accessed by a browser on another computer on your network, allowing you to perform hypervisor management through a web interface. Choose an IP address that is on the same network segment as your router (and home network). If your router is running DHCP, you want this management address to be outside of the DHCP pool.\nI\u0026rsquo;ve selected 192.168.0.10/24 as the management IP address, with the address of my router (192.168.0.1) as the gateway. Keep the management address handy. I\u0026rsquo;ve also gone with a FQDN (fully-qualified domain name) of pve.alex.home, which implies the hostname pve.\n If you want to change the management IP address later, you will need to do it in two places: (a) /etc/hosts and (b) /etc/network/interfaces. We\u0026rsquo;ll look at the latter configuration file later on.   Configuring Proxmox After the installation has finished, remove the USB drive and reboot. You\u0026rsquo;ll eventually see a prompt that asks you to configure Proxmox by visiting https://\u0026lt;MANAGEMENT-IP\u0026gt;:8006. Provided you\u0026rsquo;ve configured the network settings properly, you will be able to access the web GUI from another computer in your home network by entering that address in a browser. Once you\u0026rsquo;ve supplied your credentials (user root and the password you specified earlier) and logged in, you are ready to start configuring the hypervisor.\nEnabling software updates At this point, it\u0026rsquo;s a good idea to enable software updates. Proxmox is configured by default to access the software repositories for subscribed customers, which are not accessible to those without a subscription. We\u0026rsquo;re going to configure Proxmox to access the community repositories instead.\nLet\u0026rsquo;s take a quick look at the interface. On the left you\u0026rsquo;ve got the resource tree, a column that gives you an overview of your hypervisor (Fig. 2, left column). Underneath Datacenter, you\u0026rsquo;ve got a single node with hostname pve. One more level down lists all the VMs and logical storage devices associated with the node. At the moment there are no VMs and two shared storage objects called local and local-lvm that resulted from the default Proxmox installation options. The local-lvm object holds VM disk images, while the local object holds backup files and ISO images. We\u0026rsquo;ll be dealing with local shortly.\n  Fig. 2. Left column: Proxmox resource tree, showing the VMs and storage objects available to the node pve. Right panel: ISO images in local shared storage after uploading to the host.   The toolbar in Fig. 2 above (with title Storage \u0026lsquo;local\u0026rsquo; on node \u0026lsquo;pve\u0026rsquo; and button Help on the right) will change according to the selected resource in the tree. Clicking the pve node will bring up node-specific toolbar buttons, like Reboot, Shutdown, and Shell. Go ahead and click that Shell button.\nTime to configure the software repositories. Debian (Proxmox\u0026rsquo;s underlying operating system) makes use of apt (Advanced Package Tool) to manage and update software. We are going to navigate to the directory that holds the repository configuration, rename (and effectively disable) the config file, and create a new config file containing a link to the community repositories.\ncd /etc/apt/sources.list.d mv pve-enterprise.list pve-enterprise.list.original echo 'deb http://download.proxmox.com/debian/pve buster pve-no-subscription' \u0026gt; pve-community.list   buster is the name of the Debian release used by Proxmox 6. Make sure to use the release name for your version of Proxmox.   You can now run apt update and apt dist-upgrade to download and install all available updates.\nUploading ISO images Before we can start making VMs, we need to upload the ISO installation media. Click the local storage object  Content tab to bring up a (currently empty) list of items sitting in the storage. After using the Upload button to store the pfSense and CentOS ISO images, the list will look like Fig. 2 (right panel).\nConfiguring the virtual network As mentioned earlier, the host will have two network segments: one that allows the host to communicate with the home network, and an internal network segment, insulated by a firewall. This section talks about the configuration needed to prepare the virtualized network for the firewall.\nVirtual switches The network components available to Proxmox can be found by clicking the pve node  System tab group  Network tab. The Protectli box has six NICs, which are listed as enp[1-6]s0 in Fig. 3 below as Network Devices.\nYou\u0026rsquo;ll also see something called a Linux Bridge, named vmbr0. This behaves like a network switch, allowing for communication between devices using both virtual and physical interfaces. Currently it\u0026rsquo;s associated with one physical interface (enp1s0), through which the host is connected to the router. The bridge is also associated with Proxmox through its management IP address (192.168.0.10/24). If we connected a VM to vmbr0 and gave it an IP address from the same subnet, that VM will gain access to both Proxmox\u0026rsquo;s management interface and the router. We\u0026rsquo;ll be doing exactly this for pfSense.\n A Linux Bridge does not necessarily need an IP address, but since we want to be able to manage Proxmox from the home network, we need vmbr0 to be bound to an IP address on the home network subnet, 192.168.0.0/24.     Fig. 3. Proxmox network devices, shown with two Linux Bridges.   Forwarding between (private) networks Now we\u0026rsquo;re going to focus on the internal network segment, which needs its own Linux Bridge. Make one and call it vmbr1, without assigning an IP address or any other settings to the bridge. The internal network will make use of the subnet 192.168.1.0/24.\nAs useful as Proxmox\u0026rsquo;s web interface is, we cannot use it to completely configure the virtual network for our use case. To make this work, we need to directly edit the /etc/network/interfaces file to ask Proxmox to do two things for us:\n forward IP packets across different network segments, and use IP masquerading.  The effect of (2) will be to allow all devices in the internal network (each with their own private IP address on the internal subnet) to communicate with the outside world using a single \u0026ldquo;external\u0026rdquo; IP address \u0026ndash; the address of the host.\n I say \u0026ldquo;external\u0026rdquo; in quotes because often when we talk about NAT (network address translation), we\u0026rsquo;re mapping a private IP address to a public IP address. Here we\u0026rsquo;re mapping private IP addresses to another private IP address.   If we take a look at /etc/network/interfaces, we will see the six physical interfaces, enp[1-6]s0, as well as vmbr0 and vmbr1. The configuration for the two Linux Bridges is shown below:\nauto vmbr0 iface vmbr0 inet static address 192.168.0.10/24 gateway 192.168.0.1 bridge-ports enp1s0 bridge-stp off bridge-fd 0 auto vmbr1 iface vmbr1 inet manual bridge-ports none bridge-stp off bridge-fd 0  We can confirm that only vmbr0 has an IP address and gateway, allowing for communication between the host, router, and firewall on the 192.168.0.0/24 subnet.\nAt the end of the file, we will add the following three lines:\npost-up echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward post-up iptables -t nat -A POSTROUTING -s '192.168.1.0/24' -o vmbr0 -j MASQUERADE post-down iptables -t nat -D POSTROUTING -s '192.168.1.0/24' -o vmbr0 -j MASQUERADE  The first line enables packet forwarding after the interface has been brought up, and the next two lines conditionally add/remove a rule for Proxmox\u0026rsquo;s firewall. Let\u0026rsquo;s break it down:\n -t nat -A POSTROUTING: the rule gets added to the POSTROUTING NAT table, to alter packets as they leave the interface, -s '192.168.1.0/24': the rule applies to any packet whose source IP belongs to the internal network, -o vmbr0: matching packets get sent to interface vmbr0, -j MASQUERADE: matching packets get their source IP replaced by that of vmbr0.  In the last line, instead of adding the rule after the interface is brought up, the rule is removed after the interface is brought down.\nTo summarize, the effect of this extra configuration is to take packets that are heading out from the internal network (e.g. with source IP 192.168.1.99), replace their source IPs with 192.168.0.10, and send them on their way. When an internal VM\u0026rsquo;s network request is reciprocated by a public server, the server will send packets that are addressed to Proxmox, which will intercept and redirect those packets back through the firewall.\nInstalling pfSense We are finally ready to create our pfSense virtual machine! In this homelab iteration, the firewall is just going to have a small amount of configuration to control administrative access and configure DHCP to assign IP addresses to two CentOS VMs (a client and a server) using their MAC addresses.\nSince there\u0026rsquo;s not going to be any heavy traffic processing going on here, I\u0026rsquo;ve opted for a single-core VM (hostname pfsense) with pfSense\u0026rsquo;s minimum hardware requirements (512 MiB RAM and 4 GiB of disk space), using the Create Virtual Machine dialog to choose a VirtIO SCSI controller and VirtIO network device connected to the vmbr0 bridge.\n According to the documentation, we should use paravirtualized (VirtIO) devices where possible. Paravirtualization allows guest operating systems to talk directly to the hypervisor, which generally leads to improved performance and less virtualization overhead.   Now we\u0026rsquo;ll add another network device to the VM. In the resource tree, click the pfsense VM  Hardware tab  Add dropdown button  Network Device, to connect vmbr1. Now the pfSense VM has two NICs: net0, connected to vmbr0, and net1, connected to vmbr1. Start up the VM and install pfSense with all of the defaults.\nConfiguring pfSense After installation and a reboot, pfSense will ask whether you want to set up VLANs. We\u0026rsquo;re not doing this, but before you proceed, make sure you see two valid interfaces, vtnet0 and vtnet1, listed above the prompt. Next, you\u0026rsquo;ll get a couple more prompts:\n \u0026ldquo;Enter the WAN interface name\u0026rdquo; ‚Üí vtnetx \u0026ldquo;Enter the LAN interface name\u0026rdquo; ‚Üí vtnety   Make sure that each interface corresponds to its Linux Bridge counterpart (e.g. vtnet0 is vmbr0). Check that the listed MAC addresses match the ones found under Datacenter  pve node  pfSense VM  Hardware tab.   The WAN interface is the firewall\u0026rsquo;s untrusted entrance. If I were confident that these homelab shenanigans wouldn\u0026rsquo;t eventually disrupt my internet connectivity, I\u0026rsquo;d arrange for the firewall to handle internet traffic directly, before forwarding traffic to the home router and network through the firewall\u0026rsquo;s LAN interface. (But I\u0026rsquo;m not. At least, not yet!)\nAfter confirming the above information, pfSense will continue booting and eventually present you with a menu (Fig. 3). In my case, the router has allocated pfSense\u0026rsquo;s WAN interface an IP address, 192.168.0.180/24. That is a nice gesture, but I want to give it a static IP address. After choosing option 2, enter the WAN\u0026rsquo;s new IP address as 192.168.0.11/24 and a gateway of 192.168.0.1. Enter no when asked to revert to HTTP as the webConfigurator protocol (this is unimportant right now). Time to reboot.\n  Fig. 3. pfSense command line menu.   Using the setup wizard Once we\u0026rsquo;re back at the menu, we can access the management GUI using the WAN interface IP address, although we need to temporarily disable the firewall to access it. Choose option 8 to enter the shell, run pfctl -d to bring down the firewall, and then enter 192.168.0.11 in a browser on your home network. After supplying the default credentials (username admin, password pfsense), you\u0026rsquo;ll be brought to pfSense\u0026rsquo;s setup wizard. I\u0026rsquo;ll highlight some important configuration below (with the steps in parentheses):\n (2/9) Hostname/domain: nice to make these match your Proxmox details, (2/9) Primary/secondary DNS Server: as above, (3/9) Timezone: choose yours, (4/9) Static IP configuration: make sure these details are correct (192.168.0.11/24, with gateway 192.168.0.1), (4/9) RFC1918/bogon networks: uncheck the two boxes to allow private/non-internet routed networks through the WAN interface \u0026ndash; this firewall will of course be dealing with these kinds of networks, (5/9) Configure LAN interface: make sure these details are correct (192.168.1.1/24) \u0026ndash; this will be the gateway for the VMs in the internal network, (6/9) Set admin webGUI password: now\u0026rsquo;s a good time!  Setting the admin password will trigger an update, after which you will get kicked off the management GUI. Go ahead and reboot the pfSense VM. We haven\u0026rsquo;t yet made allowances for management access in the firewall, so once it\u0026rsquo;s ready you will have to once again disable the firewall (pfctl -d) before logging back in with your new credentials.\nPlaying nice with VirtIO If you try moving through different parts of the web interface, you might notice that it seems a bit sluggish. This comes about from an issue with using VirtIO network drivers to interface with pfSense, which can be resolved by changing a couple of settings as recommended by the documentation (section Configuring pfSense Software to work with Proxmox VirtIO).\nClick the System header menu  Advanced  Networking tab and scroll to the bottom to the Network Interfaces section. Make sure these boxes below are checked:\n Disable hardware checksum offload Disable hardware TCP segmentation offload Disable hardware large receive offload  Allowing administrative access Our next order of business is to allow ourselves administrative access, so that we don\u0026rsquo;t have to tear down our firewall every time we need to perform some management. We are going to do a couple of things here:\n define aliases to specify IP management ports, use these aliases to allow pfSense management through those ports.  To define the aliases, click the Firewall header menu  Aliases  Ports tab, and then click Add. We will allow management through ports 80 (HTTP) and 8080 (alt-HTTP). When you\u0026rsquo;ve got these ports listed as in Fig. 4 below, save and apply the changes when prompted.\n  Fig. 4. Specifying pfSense aliases.   Now we will add a rule to allow management traffic through the WAN interface. The rule we add will act on inbound packets at the interface. Click the Firewall header menu  Rules  WAN tab, and then click Add.\nStepping through the configuration:\n Edit firewall rule: pass TCP IPv4 traffic through the WAN interface \u0026ndash; you will find that the default settings under this heading work for us, Source: allow access to home network devices, so specify Network and enter 192.168.0.0/24, Destination: match traffic headed for this firewall (select this in the destination dropdown) through the management ports (fill out the Custom port ranges with the alias pfsense_admin_ports), Extra options: fill out the description with something like \u0026ldquo;allow administrative access from home network\u0026rdquo;.  After saving the new firewall rule, we will get pfSense to provide access to the management interface through the alternative HTTP port. Click the System header menu  Advanced  Admin Access tab, enter 8080 in the TCP port field, and apply the changes.\n A firewall will go through each of its rules until it finds a match, at which point it will act on the traffic according to the matching rule. If an inbound packet doesn\u0026rsquo;t match any rule, the packet gets dropped.    It\u0026rsquo;s good practice to serve the web interface on alternative HTTP port 8080, as some systems require full administrative privileges to access port numbers lower than 1024 (like the HTTP port 80, for example).   Now we can freely manage the firewall through the web interface! You can either reboot the router or run pfctrl -e to bring the firewall back online.\nCreating the internal network We\u0026rsquo;re now going to create two CentOS VMs: a client VM and server VM. In reality they will be pretty much identical (save for their NIC MAC addresses) but they will play certain roles as I learn the ropes of system administration. I will then configure pfSense to assign each VM with an IP address that allows them to communicate.\nSetting up a CentOS VM is pretty straightforward. The first one will have the hostname centos-server. It will have 1 CPU, 2 GiB RAM, 20 GiB of hard disk space, and be connected to vmbr1. Here we will choose a non-paravirtualized NIC model, the Intel E1000.\n Make sure you do not choose the VirtIO network device! With that NIC, I could ping google.com but could not curl google.com. This was the cause of hours of madness, until this forum post gave me a hint. There is apparently an issue with a VM using paravirtualized network drivers to communicate with pfSense, but it\u0026rsquo;s not at all clear why.   Once you\u0026rsquo;ve run through the installation and logged in, you should be able to access the internet through the VM (provided you\u0026rsquo;ve got a working DNS configuration). Now the VM can be cloned to yield centos-client and there will be two functional VMs on the internal network, with full internet connectivity.\nRestricting access We\u0026rsquo;re pretty close to achieving the design goal. The main issue is that right now, the firewall isn\u0026rsquo;t really doing much. Now I want to restrict access to whitelist these two CentOS VMs and nothing more. To do this, I\u0026rsquo;ll make use of pfSense\u0026rsquo;s DHCP service to map each MAC address to a static IP address on the internal network segment.\nMapping VMs to IP addresses The MAC address of a given VM can be accessed by selecting the VM in the Proxmox resource tree  Hardware tab and double-clicking the Network Device row associated with vmbr1. Grab the server and client MAC addresses and keep them handy. Incidentally, I\u0026rsquo;ll be assigning centos-server to 192.168.1.101 and centos-client to 192.168.1.102.\nLet\u0026rsquo;s head back into the pfSense web interface and click the Services header menu  DHCP Server. At the moment, the VMs are getting their IP addresses from the available range indicated at the bottom of the General Options section. Set the range to 192.168.1.220 to 192.168.1.240 and click Save. The specific range isn\u0026rsquo;t too important \u0026ndash; we just want the range not to include any of the static VM addresses.\nAt the bottom of the page there\u0026rsquo;s a section called DHCP Static Mappings for this Interface, which sounds like what we want. Click Add to add a mapping for both VMs, filling out the MAC address, client identifier, IP address, and hostname for each mapping (Fig. 5).\n  Fig. 5. Specifying DHCP static mappings for the CentOS VMs.   We can now bring a VM\u0026rsquo;s interface down and back up again to reassign the IP address, confirming the change with the last command:\nnmcli connection down ens18 nmcli connection up ens18 ip address show ens18  Blacklisting unknown devices For our final act, we are going to block traffic leaving the internal network from all unauthorized devices, i.e., anything other than centos-server and centos-client. This can be done by whitelisting the network 192.168.1.100/30 and blocking everything else.\nIn the pfSense interface, click the Firewall header menu  Rules  LAN tab. We will create a rule to pass IPv4 packets from any protocol with a source IP coming from the network 192.168.1.100/30. After disabling any other rules and applying the changes, we have successfully locked down the internal network. You can confirm this by manually setting one of the VM\u0026rsquo;s IP addresses to a non-whitelisted address and running curl google.com.\nSummary At last, the homelab is up and running! There is of course a lot that can be done to improve this setup, particularly in the way of security. I think it would be a great idea to configure VLANs and enable SSH access for firewall management in the next homelab iteration, but for now it can serve as a testbed for all sorts of administrative tasks.\n  Another solution would be to implement the lab on a cloud platform. \u0026#x21a9;\u0026#xfe0e;\n A cross-platform alternative to Rufus is Etcher. \u0026#x21a9;\u0026#xfe0e;\n See this article from Red Hat for a good discussion about how to choose a file system (although they conspicuously do not mention ZFS). \u0026#x21a9;\u0026#xfe0e;\n   ","date":1591413188,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591413188,"objectID":"3cceb86787e544da6f7af52da565d354","permalink":"https://www.remotelycurious.net/post/homelab/","publishdate":"2020-06-05T23:13:08-04:00","relpermalink":"/post/homelab/","section":"post","summary":"Or, the things I will do to avoid running multiple VMs on my laptop.","tags":["proxmox","pfsense","homelab","linux"],"title":"Building a homelab with Proxmox","type":"post"},{"authors":["AE Hadjinicolaou","SL Cloherty","YS Hung","T Kameneva","MR Ibbotson"],"categories":[],"content":"","date":1466726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466726400,"objectID":"276d777d156db4606380dd585cd7189b","permalink":"https://www.remotelycurious.net/publication/plos-one-2016/","publishdate":"2020-06-10T10:43:43-04:00","relpermalink":"/publication/plos-one-2016/","section":"publication","summary":"An investigation of how retinal ganglion cell morphology can influence intracellular responses to repeated electrical stimulation.","tags":[],"title":"Frequency responses of rat retinal ganglion cells","type":"publication"},{"authors":["AE Hadjinicolaou","H Meffin","MI Maturana","SL Cloherty","MR Ibbotson"],"categories":[],"content":"","date":1442880000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442880000,"objectID":"47ef051d9785ea813198c403085b4e4f","permalink":"https://www.remotelycurious.net/publication/clin-exp-optom-2015/","publishdate":"2020-06-10T10:44:27-04:00","relpermalink":"/publication/clin-exp-optom-2015/","section":"publication","summary":"An invited review of progress in the field of vision microprosthetics, with an emphasis on retinal research.","tags":[],"title":"Prosthetic vision: devices, patient outcomes and retinal research","type":"publication"},{"authors":["AE Hadjinicolaou","CO Savage","NV Apollo","DJ Garrett","SL Cloherty","MR Ibbotson","BJ O'Brien"],"categories":[],"content":"","date":1413504000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413504000,"objectID":"0e5b11c450c9fcf422d942c204e8f2c4","permalink":"https://www.remotelycurious.net/publication/tnsre-2014/","publishdate":"2020-06-10T10:43:07-04:00","relpermalink":"/publication/tnsre-2014/","section":"publication","summary":"This work suggests that the right choice of electrical stimulus can significantly improve the ability of a retinal microprosthesis to activate the retina.","tags":[],"title":"Optimizing the electrical stimulation of retinal ganglion cells","type":"publication"},{"authors":["AE Hadjinicolaou","RT Leung","DJ Garrett","K Ganesan","K Fox","DAX Nayagam","MN Shivdasani","H Meffin","MR Ibbotson","S Prawer","BJ O'Brien"],"categories":[],"content":"","date":1337472000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1337472000,"objectID":"3ebc9a3d5327cab21175bae389febf32","permalink":"https://www.remotelycurious.net/publication/biomaterials-2012/","publishdate":"2020-06-10T10:22:25-04:00","relpermalink":"/publication/biomaterials-2012/","section":"publication","summary":"My first publication sought to demonstrate the use of nitrogen-doped diamond as a viable material for use in a retinal microprosthesis.","tags":[],"title":"Electrical stimulation of retinal ganglion cells with diamond and the development of an all-diamond retinal prosthesis","type":"publication"}]